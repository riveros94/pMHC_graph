{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031e2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import re\n",
    "from graph.graph import AssociatedGraph\n",
    "from utils.preprocessing import create_graphs\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple, List, Literal, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3629e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class obj:\n",
    "    def __init__(self, dict1):\n",
    "        self.__dict__.update(dict1)\n",
    " \n",
    "def dict2obj(dict1):\n",
    "    return json.loads(json.dumps(dict1), object_hook=obj)\n",
    "\n",
    "args = dict2obj({\n",
    "        \"folder_path\": \"Analysis/selected_strs_renumber/without_TCR\",\n",
    "        \"manifest\": \"manifest_analysis.json\",\n",
    "        \"serd_config\": None,\n",
    "        \"files_name\": None,\n",
    "        \"output_path\": None,\n",
    "        \"run_name\": None,\n",
    "        \"check_depth\": False,\n",
    "        \"check_rsa\": True,\n",
    "        \"centroid_threshold\": 8.5,\n",
    "        \"distance_diff_threshold\": 3,\n",
    "        \"depth_filter\": None,\n",
    "        \"depth_bins\": 3,\n",
    "        \"rsa_filter\": 0.1,\n",
    "        \"rsa_bins\": 3,\n",
    "        \"distance_bins\": 3,\n",
    "        \"classes_path\": None,\n",
    "        \"exclude_waters\": False})\n",
    "\n",
    "checks = {\n",
    "        \"depth\": args.check_depth,\n",
    "        \"rsa\": args.check_rsa,\n",
    "}\n",
    "\n",
    "association_config = {\n",
    "    \"centroid_threshold\": args.centroid_threshold,\n",
    "    \"distance_diff_threshold\": args.distance_diff_threshold,\n",
    "    \"rsa_filter\": args.rsa_filter,\n",
    "    \"depth_filter\": args.depth_filter,\n",
    "    \"rsa_bins\": args.rsa_bins,\n",
    "    \"depth_bins\": args.depth_bins,\n",
    "    \"distance_bins\": args.distance_bins,\n",
    "    \"checks\": checks,\n",
    "    \"classes_path\": args.classes_path\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9d37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = {\n",
    "  \"settings\": {\n",
    "    \"run_name\": None,\n",
    "    \"output_path\": None,\n",
    "    \"debug\": True,\n",
    "    \"track_steps\": True,\n",
    "    \"centroid_threshold\": 8.5,\n",
    "    \"centroid_granularity\": \"ca_only\",\n",
    "    \"exclude_waters\": False,\n",
    "    \"check_rsa\": True,\n",
    "    \"check_depth\": False,\n",
    "    \"rsa_filter\": 0.1,\n",
    "    \"depth_filter\": 10.0,\n",
    "    \"distance_diff_threshold\": 3,\n",
    "\n",
    "    \"distance_bins\": 3,\n",
    "    \"rsa_bins\": 3,\n",
    "    \"depth_bins\": 3,\n",
    "\n",
    "    \"serd_config\": None,\n",
    "\n",
    "    \"classes_\": {\n",
    "      \"residues\": {\n",
    "        \"HID\": [\"ALA\", \"VAL\", \"LEU\", \"ILE\", \"MET\"],\n",
    "        \"POL\": [\"SER\", \"THR\", \"ASN\", \"GLN\", \"CYS\"],\n",
    "        \"POS\": [\"LYS\", \"ARG\", \"HIS\"],\n",
    "        \"NEG\": [\"ASP\", \"GLU\"],\n",
    "        \"ARO\": [\"PHE\", \"TYR\", \"TRP\"],\n",
    "        \"ESP\": [\"GLY\", \"PRO\"]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "\n",
    "  \"inputs\": [],\n",
    "  \"constrains\": {\n",
    "    \"MHC1\": {\n",
    "      \"chains\": [\"C\"],\n",
    "      \"residues\": {\n",
    "        \"A\": [18, 19, 42, 43, 44, 54, 55, 56, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 85, 89, 108, 109, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171]\n",
    "      }\n",
    "    },\n",
    "    \"MHC2\": {\n",
    "      \"chains\": [\"C\"],\n",
    "      \"residues\": {\n",
    "        \"A\": [39, 53, 54, 55, 57, 58, 60, 61, 62, 64, 65, 67, 68, 69, 71]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa42740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffMHC_diffPep = pd.read_csv(\"Analysis/crossreact_processed_diff_MHC_diff_pep_helder.csv\")\n",
    "diffMHC_SamePep = pd.read_csv(\"Analysis/crossreact_processed_diff_MHC_same_pep_helder.csv\")\n",
    "sameMHC_diffPep = pd.read_csv(\"Analysis/crossreact_processed_same_MHC_diff_pep_helder.csv\")\n",
    "rawCross = pd.read_csv(\"Analysis/crossreact_tcrs_v4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c14461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCR_ID</th>\n",
       "      <th>TRA</th>\n",
       "      <th>TRB</th>\n",
       "      <th>peptide</th>\n",
       "      <th>MHCseq</th>\n",
       "      <th>MHCseq_ref</th>\n",
       "      <th>allele</th>\n",
       "      <th>allele_blast</th>\n",
       "      <th>mismatches</th>\n",
       "      <th>Score</th>\n",
       "      <th>...</th>\n",
       "      <th>TRA_ref</th>\n",
       "      <th>TRB_ref</th>\n",
       "      <th>TCR_pair_id</th>\n",
       "      <th>MHC_allele_id</th>\n",
       "      <th>MHC_allele_id_interface</th>\n",
       "      <th>peptide_id</th>\n",
       "      <th>pMHC_id</th>\n",
       "      <th>pep_crossreact</th>\n",
       "      <th>mhc_crossreact</th>\n",
       "      <th>pmhc_crossreact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PDB4ms8</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>SPAEAGFFL</td>\n",
       "      <td>MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...</td>\n",
       "      <td>GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H-2Ld</td>\n",
       "      <td>F9Y,V13T,P16R,I24T,N31D,A50V,K132R</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PDB3tjh</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>SPLDSLWWI</td>\n",
       "      <td>MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...</td>\n",
       "      <td>GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H-2Ld</td>\n",
       "      <td>F9Y,V13T,P16R,I24T,N31D,A50V,I67V,W98R,K132R</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PDB4mxq</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>SPAPRPLDL</td>\n",
       "      <td>MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...</td>\n",
       "      <td>GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H-2Ld</td>\n",
       "      <td>F9Y,V13T,P16R,I24T,N31D,A50V,K132R</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PDB3tfk</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>QLSDVPMDL</td>\n",
       "      <td>MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...</td>\n",
       "      <td>GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H-2Ld</td>\n",
       "      <td>F9Y,V13T,P16R,I24T,N31D,A50V,I67V,W98R,K132R</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>99</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PDB4n0c</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>MPAGRPWDL</td>\n",
       "      <td>MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...</td>\n",
       "      <td>GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H-2Ld</td>\n",
       "      <td>F9Y,V13T,P16R,I24T,N31D,A50V,K132R</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...</td>\n",
       "      <td>EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>PDB7dzm</td>\n",
       "      <td>DAKTTQPPSMDCAEGRAANLPCNHSTISGNEYVYWYRQIHSQGPQY...</td>\n",
       "      <td>AGVIQSPRHEVTEMGQEVTLRCKPISGHNSLFWYRQTMMRGLELLI...</td>\n",
       "      <td>TPQDLNTML</td>\n",
       "      <td>GGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPRE...</td>\n",
       "      <td>GGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPRE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B*81:02</td>\n",
       "      <td>A1G</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>DAKTTQPPSMDCAEGRAANLPCNHSTISGNEYVYWYRQIHSQGPQY...</td>\n",
       "      <td>AGVIQSPRHEVTEMGQEVTLRCKPISGHNSLFWYRQTMMRGLELLI...</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>74</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>PDB7dzn</td>\n",
       "      <td>DAKTTQPPSMDCAEGRAANLPCNHSTISGNEYVYWYRQIHSQGPQY...</td>\n",
       "      <td>DAGVIQSPRHEVTEMGQEVTLRCKPISGHNSLFWYRQTMMRGLELL...</td>\n",
       "      <td>TPQDLNTML</td>\n",
       "      <td>MGGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPR...</td>\n",
       "      <td>GGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPRE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B*42:30</td>\n",
       "      <td>A2G</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>DAKTTQPPSMDCAEGRAANLPCNHSTISGNEYVYWYRQIHSQGPQY...</td>\n",
       "      <td>AGVIQSPRHEVTEMGQEVTLRCKPISGHNSLFWYRQTMMRGLELLI...</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>PDB8eo8</td>\n",
       "      <td>GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...</td>\n",
       "      <td>AVVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLM...</td>\n",
       "      <td>LPFDKATIM</td>\n",
       "      <td>GSHSMRYFYTAMSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPRTE...</td>\n",
       "      <td>MRVTAPRTVLLLLWGAVALTETWAGSHSMRYFYTAMSRPGRGEPRF...</td>\n",
       "      <td>B*35:01:01:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...</td>\n",
       "      <td>VVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLMA...</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "      <td>97</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>PDB8enh</td>\n",
       "      <td>GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...</td>\n",
       "      <td>AVVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLM...</td>\n",
       "      <td>LPFEKSTIM</td>\n",
       "      <td>GSHSMRYFYTAMSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPRTE...</td>\n",
       "      <td>MRVTAPRTVLLLLWGAVALTETWAGSHSMRYFYTAMSRPGRGEPRF...</td>\n",
       "      <td>B*35:01:01:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...</td>\n",
       "      <td>VVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLMA...</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>PDB8en8</td>\n",
       "      <td>GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...</td>\n",
       "      <td>VVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLMA...</td>\n",
       "      <td>LPFDKSTIM</td>\n",
       "      <td>GSHSMRYFYTAMSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPRTE...</td>\n",
       "      <td>MRVTAPRTVLLLLWGAVALTETWAGSHSMRYFYTAMSRPGRGEPRF...</td>\n",
       "      <td>B*35:01:01:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...</td>\n",
       "      <td>VVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLMA...</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TCR_ID                                                TRA  \\\n",
       "0    PDB4ms8  AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "1    PDB3tjh  AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "2    PDB4mxq  AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "3    PDB3tfk  AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "4    PDB4n0c  AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "..       ...                                                ...   \n",
       "110  PDB7dzm  DAKTTQPPSMDCAEGRAANLPCNHSTISGNEYVYWYRQIHSQGPQY...   \n",
       "111  PDB7dzn  DAKTTQPPSMDCAEGRAANLPCNHSTISGNEYVYWYRQIHSQGPQY...   \n",
       "112  PDB8eo8  GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...   \n",
       "113  PDB8enh  GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...   \n",
       "114  PDB8en8  GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...   \n",
       "\n",
       "                                                   TRB    peptide  \\\n",
       "0    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...  SPAEAGFFL   \n",
       "1    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...  SPLDSLWWI   \n",
       "2    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...  SPAPRPLDL   \n",
       "3    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...  QLSDVPMDL   \n",
       "4    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...  MPAGRPWDL   \n",
       "..                                                 ...        ...   \n",
       "110  AGVIQSPRHEVTEMGQEVTLRCKPISGHNSLFWYRQTMMRGLELLI...  TPQDLNTML   \n",
       "111  DAGVIQSPRHEVTEMGQEVTLRCKPISGHNSLFWYRQTMMRGLELL...  TPQDLNTML   \n",
       "112  AVVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLM...  LPFDKATIM   \n",
       "113  AVVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLM...  LPFEKSTIM   \n",
       "114  VVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLMA...  LPFDKSTIM   \n",
       "\n",
       "                                                MHCseq  \\\n",
       "0    MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...   \n",
       "1    MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...   \n",
       "2    MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...   \n",
       "3    MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...   \n",
       "4    MGPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRY...   \n",
       "..                                                 ...   \n",
       "110  GGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPRE...   \n",
       "111  MGGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPR...   \n",
       "112  GSHSMRYFYTAMSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPRTE...   \n",
       "113  GSHSMRYFYTAMSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPRTE...   \n",
       "114  GSHSMRYFYTAMSRPGRGEPRFIAVGYVDDTQFVRFDSDAASPRTE...   \n",
       "\n",
       "                                            MHCseq_ref         allele  \\\n",
       "0    GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...            NaN   \n",
       "1    GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...            NaN   \n",
       "2    GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...            NaN   \n",
       "3    GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...            NaN   \n",
       "4    GPHSMRYYETATSRRGLGEPRYTSVGYVDDKEFVRFDSDAENPRYE...            NaN   \n",
       "..                                                 ...            ...   \n",
       "110  GGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPRE...            NaN   \n",
       "111  GGSHSMRYFYTSVSRPGRGEPRFISVGYVDDTQFVRFDSDAASPRE...            NaN   \n",
       "112  MRVTAPRTVLLLLWGAVALTETWAGSHSMRYFYTAMSRPGRGEPRF...  B*35:01:01:01   \n",
       "113  MRVTAPRTVLLLLWGAVALTETWAGSHSMRYFYTAMSRPGRGEPRF...  B*35:01:01:01   \n",
       "114  MRVTAPRTVLLLLWGAVALTETWAGSHSMRYFYTAMSRPGRGEPRF...  B*35:01:01:01   \n",
       "\n",
       "    allele_blast                                    mismatches  Score  ...  \\\n",
       "0          H-2Ld            F9Y,V13T,P16R,I24T,N31D,A50V,K132R      3  ...   \n",
       "1          H-2Ld  F9Y,V13T,P16R,I24T,N31D,A50V,I67V,W98R,K132R      3  ...   \n",
       "2          H-2Ld            F9Y,V13T,P16R,I24T,N31D,A50V,K132R      3  ...   \n",
       "3          H-2Ld  F9Y,V13T,P16R,I24T,N31D,A50V,I67V,W98R,K132R      3  ...   \n",
       "4          H-2Ld            F9Y,V13T,P16R,I24T,N31D,A50V,K132R      3  ...   \n",
       "..           ...                                           ...    ...  ...   \n",
       "110      B*81:02                                           A1G      3  ...   \n",
       "111      B*42:30                                           A2G      3  ...   \n",
       "112          NaN                                           NaN      3  ...   \n",
       "113          NaN                                           NaN      3  ...   \n",
       "114          NaN                                           NaN      3  ...   \n",
       "\n",
       "                                               TRA_ref  \\\n",
       "0    AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "1    AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "2    AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "3    AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "4    AQSVTQPDARVTVSEGASLQLRCKYSYSATPYLFWYVQYPRQGLQM...   \n",
       "..                                                 ...   \n",
       "110  DAKTTQPPSMDCAEGRAANLPCNHSTISGNEYVYWYRQIHSQGPQY...   \n",
       "111  DAKTTQPPSMDCAEGRAANLPCNHSTISGNEYVYWYRQIHSQGPQY...   \n",
       "112  GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...   \n",
       "113  GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...   \n",
       "114  GENVEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKRPQL...   \n",
       "\n",
       "                                               TRB_ref TCR_pair_id  \\\n",
       "0    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...           0   \n",
       "1    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...           0   \n",
       "2    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...           0   \n",
       "3    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...           0   \n",
       "4    EAAVTQSPRNKVTVTGGNVTLSCRQTNSHNYMYWYRQDTGHGLRLI...           0   \n",
       "..                                                 ...         ...   \n",
       "110  AGVIQSPRHEVTEMGQEVTLRCKPISGHNSLFWYRQTMMRGLELLI...          34   \n",
       "111  AGVIQSPRHEVTEMGQEVTLRCKPISGHNSLFWYRQTMMRGLELLI...          34   \n",
       "112  VVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLMA...          35   \n",
       "113  VVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLMA...          35   \n",
       "114  VVSQHPSRVICKSGTSVKIECRSLDFQATTMFWYRQFPKQSLMLMA...          35   \n",
       "\n",
       "    MHC_allele_id MHC_allele_id_interface peptide_id pMHC_id  pep_crossreact  \\\n",
       "0               0                       0          3       3            True   \n",
       "1               5                       1         11      11            True   \n",
       "2               0                       0         18      19            True   \n",
       "3               5                       1         89      99            True   \n",
       "4               0                       0         57      61            True   \n",
       "..            ...                     ...        ...     ...             ...   \n",
       "110            25                      24         74      81           False   \n",
       "111            27                      25         74      88           False   \n",
       "112            13                       9         87      97            True   \n",
       "113            13                       9         67      74            True   \n",
       "114            13                       9         80      89            True   \n",
       "\n",
       "     mhc_crossreact  pmhc_crossreact  \n",
       "0             False             True  \n",
       "1             False             True  \n",
       "2             False             True  \n",
       "3             False             True  \n",
       "4             False             True  \n",
       "..              ...              ...  \n",
       "110            True            False  \n",
       "111            True            False  \n",
       "112           False            False  \n",
       "113           False            False  \n",
       "114           False            False  \n",
       "\n",
       "[115 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawCross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa662380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCR_ID</th>\n",
       "      <th>TCR_pair_id</th>\n",
       "      <th>MHC_allele_id</th>\n",
       "      <th>peptide_id</th>\n",
       "      <th>pMHC_id</th>\n",
       "      <th>PDB_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PDB4ms8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4MS8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PDB3tjh</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3TJH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PDB4mxq</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>4MXQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PDB3tfk</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>99</td>\n",
       "      <td>3TFK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PDB4n0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>4N0C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>PDB7dzm</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>74</td>\n",
       "      <td>81</td>\n",
       "      <td>7DZM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>PDB7dzn</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>7DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>PDB8eo8</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>97</td>\n",
       "      <td>8EO8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>PDB8enh</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>8ENH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>PDB8en8</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>8EN8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TCR_ID  TCR_pair_id  MHC_allele_id  peptide_id  pMHC_id PDB_ID\n",
       "0    PDB4ms8            0              0           3        3   4MS8\n",
       "1    PDB3tjh            0              5          11       11   3TJH\n",
       "2    PDB4mxq            0              0          18       19   4MXQ\n",
       "3    PDB3tfk            0              5          89       99   3TFK\n",
       "4    PDB4n0c            0              0          57       61   4N0C\n",
       "..       ...          ...            ...         ...      ...    ...\n",
       "110  PDB7dzm           34             25          74       81   7DZM\n",
       "111  PDB7dzn           34             27          74       88   7DZN\n",
       "112  PDB8eo8           35             13          87       97   8EO8\n",
       "113  PDB8enh           35             13          67       74   8ENH\n",
       "114  PDB8en8           35             13          80       89   8EN8\n",
       "\n",
       "[115 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossDf = rawCross[[\"TCR_ID\", \"TCR_pair_id\", \"MHC_allele_id\", \"peptide_id\", \"pMHC_id\", \"PDB_ID\"]]\n",
    "crossDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0dffbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protein_keys(original_graphs: dict):\n",
    "    keys = list(original_graphs.keys())\n",
    "    if all(isinstance(k, str) and k.isdigit() for k in keys):\n",
    "        return [str(i) for i in sorted(map(int, keys))]\n",
    "    return keys\n",
    "\n",
    "# ---------- projection helpers ----------\n",
    "def project_nodes_unique(frame_nodes, p):\n",
    "    return set(n[p] for n in frame_nodes)\n",
    "\n",
    "def project_nodes_instances(frame_nodes, p):\n",
    "    return [n[p] for n in frame_nodes]\n",
    "\n",
    "def chain_signature(node_tuple):\n",
    "    \"\"\"Map an associated node tuple -> chain signature string, e.g. ('A:ARG:23','A:ARG:34') -> 'AA'.\"\"\"\n",
    "    chains = []\n",
    "    for lab in node_tuple:\n",
    "        # tolerate tuples of tuples or plain strings\n",
    "        s = lab if isinstance(lab, str) else str(lab)\n",
    "        chains.append(s.split(\":\")[0] if \":\" in s else s)\n",
    "    return \"\".join(chains)\n",
    "\n",
    "def unique_chain_signatures(frame_nodes):\n",
    "    \"\"\"Return a sorted, de-duplicated list of chain signatures present in this frame.\"\"\"\n",
    "    sigs = {chain_signature(n) for n in frame_nodes}\n",
    "    return sorted(sigs)\n",
    "\n",
    "def chain_combo_key(node_tuple) -> str:\n",
    "    \"\"\"e.g., ('A:ARG:23','A:ARG:34') -> 'AA'.\"\"\"\n",
    "    return ''.join(str(part).split(':', 1)[0] for part in node_tuple)\n",
    "\n",
    "# ---------- per-protein node metrics ----------\n",
    "def  node_similarity_for_protein(frame, original_graphs, protein_keys, p):\n",
    "    nodes_assoc = frame.get(\"nodes\", [])\n",
    "    if not nodes_assoc:\n",
    "        return None\n",
    "\n",
    "    prot_key = protein_keys[p]\n",
    "    og = original_graphs[prot_key]\n",
    "    prot_name = og.get(\"name\", prot_key)\n",
    "\n",
    "    Vp = set(og[\"nodes\"]) \n",
    "\n",
    "    inst = project_nodes_instances(nodes_assoc, p)\n",
    "    Up   = set(inst)\n",
    "\n",
    "    total_orig = len(Vp) if Vp else 0\n",
    "    node_coverage = (len(Up) / total_orig) if total_orig else 0.0\n",
    "\n",
    "    total_inst = len(inst)\n",
    "    unique_cnt = len(Up)\n",
    "    duplication_ratio = (len(Up) / total_inst) if total_inst else 1.0\n",
    "    duplication_rate  = 1.0 - duplication_ratio\n",
    "    avg_multiplicity  = (total_inst / unique_cnt) if unique_cnt else float('inf')\n",
    "\n",
    "    groups = defaultdict(set)  # chain_key -> set of unique residues (for protein p)\n",
    "    for node_tuple in nodes_assoc:\n",
    "        key = ''.join(str(part).split(':', 1)[0] for part in node_tuple) # ('A:ARG:23','A:ARG:34') -> 'AA'.\n",
    "        groups[key].add(node_tuple[p])  # only the residue from protein p\n",
    "\n",
    "    unique_nodes_per_chain = {k: len(v) for k, v in groups.items()}\n",
    "    # store as JSON so it round-trips through CSV cleanly\n",
    "    unique_nodes_per_chain_json = json.dumps(unique_nodes_per_chain, ensure_ascii=False)\n",
    "\n",
    "    return dict(\n",
    "        protein_index=p,\n",
    "        protein_key=prot_key,\n",
    "        protein_name=prot_name,\n",
    "        total_nodes_associated=len(nodes_assoc),\n",
    "        total_nodes_original=total_orig,\n",
    "        frame_nodes_instances=total_inst,\n",
    "        frame_nodes_unique=len(Up),\n",
    "        node_coverage=node_coverage,\n",
    "        duplication_ratio=duplication_ratio,\n",
    "        duplication_rate=duplication_rate,\n",
    "        avg_multiplicity=avg_multiplicity,\n",
    "        unique_nodes_per_chain=unique_nodes_per_chain_json\n",
    "    )\n",
    "\n",
    "def wmean(x, w):\n",
    "    x = np.asarray(x, float); w = np.asarray(w, float)\n",
    "    s = w.sum()\n",
    "    return float(np.sum(x*w)/s) if s > 0 else np.nan\n",
    "\n",
    "def wstd(x, w):\n",
    "    x = np.asarray(x, float); w = np.asarray(w, float)\n",
    "    m = wmean(x, w)\n",
    "    s = w.sum()\n",
    "    return float(np.sqrt(np.sum(w*(x-m)**2)/s)) if s > 0 else np.nan\n",
    "\n",
    "def wmedian(x, w):\n",
    "    x = np.asarray(x, float); w = np.asarray(w, float)\n",
    "    if w.sum() == 0: return np.nan\n",
    "    order = np.argsort(x); x = x[order]; w = w[order]\n",
    "    cw = np.cumsum(w)/w.sum()\n",
    "    return float(x[np.searchsorted(cw, 0.5)])\n",
    "\n",
    "def wtrimmed_mean(x, w, trim=0.10):\n",
    "    x = np.asarray(x, float); w = np.asarray(w, float)\n",
    "    if w.sum() == 0: return np.nan\n",
    "    order = np.argsort(x); x = x[order]; w = w[order]\n",
    "    cw = np.cumsum(w)/w.sum()\n",
    "    keep = (cw >= trim) & (cw <= 1.0-trim)\n",
    "    if not np.any(keep): keep = np.ones_like(cw, dtype=bool)\n",
    "    return wmean(x[keep], w[keep])\n",
    "\n",
    "def ivw_mean_proportions(cov, n):\n",
    "    cov = np.asarray(cov, float); n = np.asarray(n, float)\n",
    "    p = ((cov*n) + 0.5) / (n + 1.0)\n",
    "    var = p*(1.0-p) / (n + 1.0) + 1e-12\n",
    "    w = 1.0/var\n",
    "    return wmean(p, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95837ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- frame-level summary (nodes only) ----------\n",
    "def summarize_frame_nodes(df_fp_nodes_for_frame):\n",
    "    if df_fp_nodes_for_frame.empty:\n",
    "        return {}\n",
    "    cov = df_fp_nodes_for_frame[\"node_coverage\"].values\n",
    "    n   = df_fp_nodes_for_frame[\"total_nodes_original\"].values\n",
    "    w   = n\n",
    "\n",
    "    return {\n",
    "        \"node_cov_wmean\":       wmean(cov, w),\n",
    "        \"node_cov_wmedian\":     wmedian(cov, w),\n",
    "        \"node_cov_wtrimmed\":    wtrimmed_mean(cov, w, trim=0.10),\n",
    "        \"node_cov_ivw_meta\":    ivw_mean_proportions(cov, n),\n",
    "        \"node_cov_wstd\":        wstd(cov, w),\n",
    "        \"node_cov_p10\":         float(np.percentile(cov, 10)),\n",
    "        \"node_cov_p50\":         float(np.percentile(cov, 50)),\n",
    "        \"node_cov_p90\":         float(np.percentile(cov, 90)),\n",
    "        \"n_proteins\":           int(len(cov)),\n",
    "        \"mean_dup_rate\":        float(df_fp_nodes_for_frame.get(\"duplication_rate\", pd.Series([np.nan])).mean()),\n",
    "        \"mean_graph_size\":      float(np.mean(n)),\n",
    "        \"sum_graph_size\":       int(np.sum(n)),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# ---------- evaluate a single frame ----------\n",
    "def evaluate_frame_nodes(component_id, frame_id, data):\n",
    "    comp_key = str(component_id)\n",
    "    frm_key  = str(frame_id)\n",
    "    frame = data[comp_key][\"frames\"][frm_key]\n",
    "\n",
    "    original_graphs = data[\"original_graphs\"]\n",
    "    protein_keys = get_protein_keys(original_graphs)\n",
    "\n",
    "    nodes_assoc = frame.get(\"nodes\", [])\n",
    "    chain_sigs = unique_chain_signatures(nodes_assoc)\n",
    "    n_unique_chain_sigs = len(chain_sigs)\n",
    "\n",
    "    rows = []\n",
    "    if nodes_assoc:\n",
    "        n_prot = len(nodes_assoc[0])\n",
    "        for p in range(n_prot):\n",
    "            r = node_similarity_for_protein(frame, original_graphs, protein_keys, p)\n",
    "            if r is not None:\n",
    "                rows.append(r)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        summary = {}\n",
    "    else:\n",
    "        summary = dict(\n",
    "            component=component_id,\n",
    "            frame=frame_id,\n",
    "            n_proteins=len(df),\n",
    "            node_cov_mean=float(df[\"node_coverage\"].mean()),\n",
    "            node_cov_median=float(df[\"node_coverage\"].median()),\n",
    "            node_cov_min=float(df[\"node_coverage\"].min()),\n",
    "            node_cov_std=float(df[\"node_coverage\"].std(ddof=0) if len(df)>1 else 0.0),\n",
    "            dup_ratio_mean=float(df[\"duplication_ratio\"].mean()),\n",
    "            unique_chain_signatures=chain_sigs,                # NEW: list like ['AA','AC',...]\n",
    "            n_unique_chain_signatures=n_unique_chain_sigs      # NEW: integer count\n",
    "        )\n",
    "    return df, summary\n",
    "\n",
    "# ---------- evaluate ALL frames (nodes only) ----------\n",
    "def evaluate_all_frames_nodes(json_path):\n",
    "    data = json.loads(Path(json_path).read_text())\n",
    "    component_ids = [k for k in data.keys() if k != \"original_graphs\"]\n",
    "    try:\n",
    "        component_ids = sorted(component_ids, key=lambda x: int(x))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    all_fp, summaries = [], []\n",
    "    for comp_id in component_ids:\n",
    "        frames = data[comp_id][\"frames\"]\n",
    "        frame_ids = list(frames.keys())\n",
    "        try:\n",
    "            frame_ids = sorted(frame_ids, key=lambda x: int(x))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        for frm_id in frame_ids:\n",
    "            df_fp, summ = evaluate_frame_nodes(comp_id, frm_id, data)\n",
    "            if not df_fp.empty:\n",
    "                df_fp.insert(0, \"component_id\", comp_id)\n",
    "                df_fp.insert(1, \"frame_id\", frm_id)\n",
    "                all_fp.append(df_fp)\n",
    "            if summ:\n",
    "                summaries.append(summ)\n",
    "\n",
    "    df_fp_nodes = pd.concat(all_fp, ignore_index=True) if all_fp else pd.DataFrame()\n",
    "    df_frames_nodes = pd.DataFrame(summaries).sort_values(\n",
    "        [\"node_cov_mean\",\"node_cov_median\",\"node_cov_min\",\"node_cov_std\"],\n",
    "        ascending=[False, False, False, True]\n",
    "    )\n",
    "    return df_fp_nodes, df_frames_nodes\n",
    "\n",
    "def evaluate_all_frames_nodes_weighted(json_path):\n",
    "    df_fp_nodes, _ = evaluate_all_frames_nodes(json_path)\n",
    "\n",
    "    summaries = []\n",
    "    if df_fp_nodes.empty:\n",
    "        return df_fp_nodes, pd.DataFrame()\n",
    "\n",
    "    for (comp_id, frame_id), g in df_fp_nodes.groupby([\"component_id\", \"frame_id\"], dropna=False):\n",
    "        s = summarize_frame_nodes(g)\n",
    "        s.update({\"component_id\": comp_id, \"frame_id\": frame_id})\n",
    "        summaries.append(s)\n",
    "\n",
    "    df_frames_nodes_w = pd.DataFrame(summaries)\n",
    "    cols = [\"component_id\", \"frame_id\"] + [c for c in df_frames_nodes_w.columns if c not in (\"component_id\", \"frame_id\")]\n",
    "    df_frames_nodes_w = df_frames_nodes_w[cols]\n",
    "\n",
    "    df_frames_nodes_w = df_frames_nodes_w.sort_values(\n",
    "        [\"node_cov_wmean\",\"node_cov_wmedian\",\"node_cov_p10\",\"node_cov_wstd\"],\n",
    "        ascending=[False, False, False, True]\n",
    "    )\n",
    "    return df_fp_nodes, df_frames_nodes_w\n",
    "\n",
    "# --- Helpers ---------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _make_json_from_associated_graph(G, out_json: Path) -> None:\n",
    "    \"\"\"\n",
    "    Serialize an AssociatedGraph into the expected JSON format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : AssociatedGraph\n",
    "        Instance already built.\n",
    "    out_json : pathlib.Path\n",
    "        Output path (will be created/overwritten).\n",
    "    \"\"\"\n",
    "    graphs_raw = G.graph_data\n",
    "    payload: Dict = {\"original_graphs\": {}}\n",
    "\n",
    "    for graph_raw in graphs_raw:\n",
    "        pdb_file = graph_raw[\"pdb_file\"]\n",
    "        _id = graph_raw[\"id\"]\n",
    "\n",
    "        m = re.search(r'noTCR_([A-Za-z0-9]{4})\\.trunc', pdb_file, re.IGNORECASE)\n",
    "        name = m[1] if m else f\"id{_id}\"\n",
    "\n",
    "        nodes = list(graph_raw[\"graph\"].nodes)\n",
    "        edges = list(graph_raw[\"graph\"].edges)\n",
    "        neighbors = {str(n): [str(nb) for nb in graph_raw[\"graph\"].neighbors(n)] for n in nodes}\n",
    "\n",
    "        payload[\"original_graphs\"][_id] = {\n",
    "            \"name\": name,\n",
    "            \"nodes\": nodes,\n",
    "            \"edges\": edges,\n",
    "            \"neighbors\": neighbors,\n",
    "        }\n",
    "\n",
    "    for j, comps in enumerate(G.associated_graphs):\n",
    "        payload[j] = {\"comp\": j, \"frames\": {}}\n",
    "        for i in range(len(comps[0])):\n",
    "            nodes = list(comps[0][i].nodes)\n",
    "            edges = list(comps[0][i].edges)\n",
    "            neighbors = {str(n): [str(nb) for nb in comps[0][i].neighbors(n)] for n in nodes}\n",
    "            payload[j][\"frames\"][i] = {\"nodes\": nodes, \"edges\": edges, \"neighbors\": neighbors}\n",
    "\n",
    "    out_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(payload, f, indent=4)\n",
    "\n",
    "\n",
    "def _save_eval_tables(out_dir: Path, df_fp_nodes: pd.DataFrame, df_frames_nodes_w: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Save per-run evaluation tables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    out_dir : pathlib.Path\n",
    "        Destination directory.\n",
    "    df_fp_nodes : pandas.DataFrame\n",
    "    df_frames_nodes_w : pandas.DataFrame\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if not df_fp_nodes.empty:\n",
    "        df_fp_nodes.to_csv(out_dir / \"nodes_per_protein.csv\", index=False)\n",
    "    if not df_frames_nodes_w.empty:\n",
    "        cols = list(df_frames_nodes_w.columns)\n",
    "        for lead in [\"component_id\", \"frame_id\"]:\n",
    "            if lead in cols:\n",
    "                cols = [lead] + [c for c in cols if c != lead]\n",
    "        df_frames_nodes_w[cols].to_csv(out_dir / \"nodes_summary_weighted.csv\", index=False)\n",
    "\n",
    "\n",
    "def _build_associated_graph(files_name: str, run_name: str, out_dir: Path, manifest: Dict):\n",
    "    \"\"\"\n",
    "    Build graphs + AssociatedGraph and persist JSON.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    files_name : str\n",
    "        Comma-separated file list passed to `args.files_name`.\n",
    "    run_name : str\n",
    "        Run identifier.\n",
    "    out_dir : pathlib.Path\n",
    "        Output directory.\n",
    "    args : Any\n",
    "        Argument namespace consumed by `create_graphs`.\n",
    "    association_config : dict\n",
    "        Passed to AssociatedGraph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (G, json_path) : tuple\n",
    "        AssociatedGraph instance and JSON path written.\n",
    "    \"\"\"\n",
    "    manifest[\"inputs\"] = [\n",
    "        {\n",
    "        \"path\": files_name,\n",
    "        \"enable_tui\": False,\n",
    "        \"extensions\": [\".pdb\", \".pdb.gz\", \".cif\"],\n",
    "        \"constrains\": [\n",
    "            { \"name\": \"MHC1\"}\n",
    "        ]\n",
    "        }\n",
    "    ]\n",
    "    manifest[\"settings\"][\"run_name\"] = run_name\n",
    "    manifest[\"settings\"][\"output_path\"] = str(out_dir)\n",
    "\n",
    "    graphs = create_graphs(manifest)\n",
    "    S = manifest[\"settings\"]\n",
    "    checks = {\n",
    "        \"depth\": S.get(\"check_depth\"),\n",
    "        \"rsa\":   S.get(\"check_rsa\"),\n",
    "    }\n",
    "    association_config = {\n",
    "        \"centroid_threshold\":          S.get(\"centroid_threshold\"),\n",
    "        \"distance_diff_threshold\":     S.get(\"distance_diff_threshold\"),\n",
    "        \"rsa_filter\":                  S.get(\"rsa_filter\"),\n",
    "        \"depth_filter\":                S.get(\"depth_filter\"),\n",
    "        \"rsa_bins\":                    S.get(\"rsa_bins\"),\n",
    "        \"depth_bins\":                  S.get(\"depth_bins\"),\n",
    "        \"distance_bins\":               S.get(\"distance_bins\"),\n",
    "        \"checks\":                      checks,\n",
    "        \"exclude_waters\":              S.get(\"exclude_waters\"),\n",
    "        \"classes\": S.get(\"classes\", {}),\n",
    "    }\n",
    "    G = AssociatedGraph(\n",
    "        graphs=graphs,\n",
    "        output_path=manifest[\"settings\"][\"output_path\"],\n",
    "        run_name=manifest[\"settings\"][\"run_name\"],\n",
    "        association_config=association_config\n",
    "    )\n",
    "    # Optional figures\n",
    "    G.draw_graph_interactive(show=False, save=True)\n",
    "    G.align_all_frames()\n",
    "    G.create_pdb_per_protein()\n",
    "\n",
    "    json_path = out_dir / f\"graph_{run_name}.json\"\n",
    "    _make_json_from_associated_graph(G, json_path)\n",
    "    return G, json_path\n",
    "\n",
    "\n",
    "# --- Public API ------------------------------------------------------------\n",
    "\n",
    "def run_allxall_per_group(\n",
    "    cross_df: pd.DataFrame,\n",
    "    manifest: dict,\n",
    "    root: str = \"Analysis/CrossGraphs\"\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run the \"All × All\" flow once per TCR_pair_id and aggregate outputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cross_df : pandas.DataFrame\n",
    "        Must contain columns 'TCR_pair_id' and 'PDB_ID'.\n",
    "    args : Any\n",
    "        Namespace consumed by `create_graphs`.\n",
    "    association_config : dict\n",
    "        Passed to AssociatedGraph.\n",
    "    root : str, default \"Analysis/CrossGraphs\"\n",
    "        Root output directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (df_all_fp, df_all_frames) : tuple of DataFrame\n",
    "        Global aggregates across groups (can be empty DataFrames).\n",
    "    \"\"\"\n",
    "    root = Path(root)\n",
    "    all_fp, all_frames = [], []\n",
    "\n",
    "    for pair_id, group in cross_df.groupby(\"TCR_pair_id\"):\n",
    "        group_dir = root / str(pair_id) / \"All\"\n",
    "        pdb_ids = [str(x).strip() for x in group[\"PDB_ID\"]]\n",
    "        files = [f\"Analysis/selected_strs_renumber/without_TCR/noTCR_{pid.lower()}.trunc.fit_renum.pdb\" for pid in pdb_ids]\n",
    "\n",
    "        files_name = \",\".join(files)\n",
    "        run_name = str(pair_id)\n",
    "\n",
    "        try:\n",
    "            _, json_path = _build_associated_graph(files_name, run_name, group_dir, manifest)\n",
    "        except Exception as e:\n",
    "            print(f\"[SKIP] Could not build group {pair_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df_fp_nodes, df_frames_nodes_w = evaluate_all_frames_nodes_weighted(str(json_path))\n",
    "            if \"frame_nodes_unique\" in df_fp_nodes.columns and \"total_nodes_associated\" not in df_fp_nodes.columns:\n",
    "                df_fp_nodes[\"total_nodes_associated\"] = df_fp_nodes[\"frame_nodes_unique\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SKIP] Evaluation failed for {pair_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        out_dir = group_dir\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if not df_fp_nodes.empty:\n",
    "            df_fp_nodes.to_csv(out_dir / \"nodes_per_protein.csv\", index=False)\n",
    "            df_fp_nodes.insert(0, \"pair_id\", pair_id)\n",
    "            all_fp.append(df_fp_nodes)\n",
    "        if not df_frames_nodes_w.empty:\n",
    "            cols = list(df_frames_nodes_w.columns)\n",
    "            for lead in [\"component_id\", \"frame_id\"]:\n",
    "                if lead in cols:\n",
    "                    cols = [lead] + [c for c in cols if c != lead]\n",
    "            df_frames_nodes_w[cols].to_csv(out_dir / \"nodes_summary_weighted.csv\", index=False)\n",
    "            df_frames_nodes_w.insert(0, \"pair_id\", pair_id)\n",
    "            all_frames.append(df_frames_nodes_w)\n",
    "\n",
    "        _save_eval_tables(group_dir, df_fp_nodes, df_frames_nodes_w)\n",
    "\n",
    "    df_all_fp = pd.concat(all_fp, ignore_index=True) if all_fp else pd.DataFrame()\n",
    "    df_all_frames = pd.concat(all_frames, ignore_index=True) if all_frames else pd.DataFrame()\n",
    "\n",
    "    if not df_all_fp.empty:\n",
    "        df_all_fp.to_csv(root / \"ALL_nodes_per_protein.csv\", index=False)\n",
    "    if not df_all_frames.empty:\n",
    "        lead = [\"pair_id\", \"component_id\", \"frame_id\"]\n",
    "        cols = lead + [c for c in df_all_frames.columns if c not in lead]\n",
    "        df_all_frames = df_all_frames[cols]\n",
    "        df_all_frames.to_csv(root / \"ALL_nodes_summary_weighted.csv\", index=False)\n",
    "\n",
    "    print(\"All×All completed.\")\n",
    "    return df_all_fp, df_all_frames\n",
    "\n",
    "\n",
    "def run_pairwise_per_group(\n",
    "    cross_df: pd.DataFrame,\n",
    "    manifest: dict,\n",
    "    root: str = \"Analysis/CrossGraphs\",\n",
    "    score_column: str = \"node_cov_wmean\"\n",
    ") -> Dict[str, Dict[str, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Run the Pairwise flow (within each TCR_pair_id) and build similarity matrices.\n",
    "    For each pair, also save the standard per-run evaluation tables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cross_df : pandas.DataFrame\n",
    "        Must contain columns 'TCR_pair_id' and 'PDB_ID'.\n",
    "    args : Any\n",
    "        Namespace consumed by `create_graphs`.\n",
    "    association_config : dict\n",
    "        Passed to AssociatedGraph.\n",
    "    root : str, default \"Analysis/CrossGraphs\"\n",
    "        Root output directory.\n",
    "    score_column : str, default \"node_cov_wmean\"\n",
    "        Frame-level column used to score a pair.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping pair_id -> {\"max\": DataFrame, \"mean\": DataFrame}\n",
    "    \"\"\"\n",
    "    out: Dict[str, Dict[str, pd.DataFrame]] = {}\n",
    "\n",
    "    for pair_id, group in cross_df.groupby(\"TCR_pair_id\"):\n",
    "        refs = [str(x).strip() for x in group[\"PDB_ID\"]]\n",
    "        files_map = {r: f\"noTCR_{r.lower()}.trunc.fit_renum.pdb\" for r in refs}\n",
    "\n",
    "        idx = refs\n",
    "        M_max = pd.DataFrame(0.0, index=idx, columns=idx)\n",
    "        M_mean = pd.DataFrame(0.0, index=idx, columns=idx)\n",
    "\n",
    "        group_dir = Path(root) / str(pair_id) / \"Pairs\"\n",
    "        group_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for r1, r2 in combinations(refs, 2):\n",
    "            files_name = \",\".join([files_map[r1], files_map[r2]])\n",
    "            run_name = f\"{pair_id}_{r1}_{r2}\"\n",
    "            out_dir = group_dir / f\"{r1}_{r2}\"\n",
    "\n",
    "            try:\n",
    "                _, json_path = _build_associated_graph(files_name, run_name, out_dir, manifest)\n",
    "            except Exception as e:\n",
    "                print(f\"[SKIP] Could not build pair ({r1},{r2}): {e}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                df_fp_nodes, df_frames_nodes_w = evaluate_all_frames_nodes_weighted(str(json_path))\n",
    "                if \"frame_nodes_unique\" in df_fp_nodes.columns and \"total_nodes_associated\" not in df_fp_nodes.columns:\n",
    "                    df_fp_nodes[\"total_nodes_associated\"] = df_fp_nodes[\"frame_nodes_unique\"]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[SKIP] Evaluation failed for pair ({r1},{r2}): {e}\")\n",
    "                continue\n",
    "\n",
    "            # Save standard per-run outputs for the pair\n",
    "            _save_eval_tables(out_dir, df_fp_nodes, df_frames_nodes_w)\n",
    "\n",
    "            # Pair score from frames\n",
    "            if not df_frames_nodes_w.empty and score_column in df_frames_nodes_w.columns:\n",
    "                max_score = float(df_frames_nodes_w[score_column].max())\n",
    "                mean_score = float(df_frames_nodes_w[score_column].mean())\n",
    "            else:\n",
    "                max_score = 0.0\n",
    "                mean_score = 0.0\n",
    "\n",
    "            M_max.loc[r1, r2] = M_max.loc[r2, r1] = max_score\n",
    "            M_mean.loc[r1, r2] = M_mean.loc[r2, r1] = mean_score\n",
    "            M_max.loc[r1, r1] = M_max.loc[r2, r2] = 1.0\n",
    "            M_mean.loc[r1, r1] = M_mean.loc[r2, r2] = 1.0\n",
    "\n",
    "        # Save matrices for the group\n",
    "        M_max.to_csv(group_dir / f\"matrix_{score_column}_MAX.csv\")\n",
    "        M_mean.to_csv(group_dir / f\"matrix_{score_column}_MEAN.csv\")\n",
    "        print(f\"Pairwise matrices saved in {group_dir}\")\n",
    "\n",
    "        out[str(pair_id)] = {\"max\": M_max, \"mean\": M_mean}\n",
    "\n",
    "    print(\"Pairwise completed.\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_cross_analysis(\n",
    "    mode: Literal[\"all\", \"pairwise\", \"both\"],\n",
    "    cross_df: pd.DataFrame,\n",
    "    manifest: dict,\n",
    "    root: str = \"Analysis/CrossGraphs\",\n",
    "    score_column: str = \"node_cov_wmean\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Unified entry point for running All×All, Pairwise, or both.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mode : {\"all\", \"pairwise\", \"both\"}\n",
    "        Which analysis to run.\n",
    "    cross_df : pandas.DataFrame\n",
    "        Must contain columns 'TCR_pair_id' and 'PDB_ID'.\n",
    "    args : Any\n",
    "        Namespace consumed by `create_graphs`.\n",
    "    association_config : dict\n",
    "        Passed to AssociatedGraph.\n",
    "    root : str, default \"Analysis/CrossGraphs\"\n",
    "        Root output directory.\n",
    "    score_column : str, default \"node_cov_wmean\"\n",
    "        Frame-level column used to score a pair (Pairwise mode).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Results container. Keys present depend on the selected mode:\n",
    "        - \"all\": {\"df_all_fp\": DataFrame, \"df_all_frames\": DataFrame}\n",
    "        - \"pairwise\": {\"matrices\": dict(pair_id -> {\"max\": df, \"mean\": df})}\n",
    "        - \"both\": union of the above.\n",
    "    \"\"\"\n",
    "    results: Dict[str, object] = {}\n",
    "\n",
    "    if mode in (\"all\", \"both\"):\n",
    "        df_all_fp, df_all_frames = run_allxall_per_group(cross_df, manifest, root=root)\n",
    "        results[\"all\"] = {\"df_all_fp\": df_all_fp, \"df_all_frames\": df_all_frames}\n",
    "\n",
    "    if mode in (\"pairwise\", \"both\"):\n",
    "        matrices = run_pairwise_per_group(cross_df, manifest, root=root, score_column=score_column)\n",
    "        results[\"pairwise\"] = {\"matrices\": matrices}\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b012a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elementare/GithubProjects/pMHC_graph/core/pdb_graph_builder.py:445: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  centroids = df.groupby(\"node_id\", sort=False, group_keys=False).apply(_centroid_for_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph exposed_residues created with success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elementare/GithubProjects/pMHC_graph/core/pdb_graph_builder.py:445: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  centroids = df.groupby(\"node_id\", sort=False, group_keys=False).apply(_centroid_for_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph exposed_residues created with success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elementare/GithubProjects/pMHC_graph/core/pdb_graph_builder.py:445: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  centroids = df.groupby(\"node_id\", sort=False, group_keys=False).apply(_centroid_for_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph exposed_residues created with success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elementare/GithubProjects/pMHC_graph/core/pdb_graph_builder.py:445: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  centroids = df.groupby(\"node_id\", sort=False, group_keys=False).apply(_centroid_for_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph exposed_residues created with success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elementare/GithubProjects/pMHC_graph/core/pdb_graph_builder.py:445: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  centroids = df.groupby(\"node_id\", sort=False, group_keys=False).apply(_centroid_for_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph exposed_residues created with success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elementare/GithubProjects/pMHC_graph/core/pdb_graph_builder.py:445: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  centroids = df.groupby(\"node_id\", sort=False, group_keys=False).apply(_centroid_for_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph exposed_residues created with success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elementare/GithubProjects/pMHC_graph/core/pdb_graph_builder.py:445: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  centroids = df.groupby(\"node_id\", sort=False, group_keys=False).apply(_centroid_for_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph exposed_residues created with success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elementare/GithubProjects/pMHC_graph/core/pdb_graph_builder.py:445: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  centroids = df.groupby(\"node_id\", sort=False, group_keys=False).apply(_centroid_for_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph exposed_residues created with success!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res_both \u001b[38;5;241m=\u001b[39m \u001b[43mrun_cross_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mboth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrossDf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanifest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanifest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnalysis/CrossGraphs_10_CA_NewMethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 469\u001b[0m, in \u001b[0;36mrun_cross_analysis\u001b[0;34m(mode, cross_df, manifest, root, score_column)\u001b[0m\n\u001b[1;32m    466\u001b[0m results: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mobject\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 469\u001b[0m     df_all_fp, df_all_frames \u001b[38;5;241m=\u001b[39m \u001b[43mrun_allxall_per_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanifest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_all_fp\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_all_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_all_frames\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_all_frames}\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpairwise\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "Cell \u001b[0;32mIn[9], line 298\u001b[0m, in \u001b[0;36mrun_allxall_per_group\u001b[0;34m(cross_df, manifest, root)\u001b[0m\n\u001b[1;32m    295\u001b[0m run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pair_id)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     _, json_path \u001b[38;5;241m=\u001b[39m \u001b[43m_build_associated_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanifest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SKIP] Could not build group \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 244\u001b[0m, in \u001b[0;36m_build_associated_graph\u001b[0;34m(files_name, run_name, out_dir, manifest)\u001b[0m\n\u001b[1;32m    228\u001b[0m checks \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m: S\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrsa\u001b[39m\u001b[38;5;124m\"\u001b[39m:   S\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_rsa\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    231\u001b[0m }\n\u001b[1;32m    232\u001b[0m association_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcentroid_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:          S\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcentroid_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance_diff_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:     S\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance_diff_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m\"\u001b[39m: S\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[1;32m    243\u001b[0m }\n\u001b[0;32m--> 244\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mAssociatedGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanifest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msettings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanifest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msettings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43massociation_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massociation_config\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# Optional figures\u001b[39;00m\n\u001b[1;32m    251\u001b[0m G\u001b[38;5;241m.\u001b[39mdraw_graph_interactive(show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/GithubProjects/pMHC_graph/graph/graph.py:166\u001b[0m, in \u001b[0;36mAssociatedGraph.__init__\u001b[0;34m(self, graphs, output_path, run_name, association_config)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_name \u001b[38;5;241m=\u001b[39m run_name\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_graph_data()\n\u001b[0;32m--> 166\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43massociation_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massociation_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(result)\n",
      "File \u001b[0;32m~/GithubProjects/pMHC_graph/utils/tools.py:902\u001b[0m, in \u001b[0;36massociation_product\u001b[0;34m(graph_data, config, debug)\u001b[0m\n\u001b[1;32m    899\u001b[0m save(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomp_id_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomp_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrices_mul\u001b[39m\u001b[38;5;124m\"\u001b[39m, matrices_mul)\n\u001b[1;32m    900\u001b[0m save(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomp_id_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomp_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaps_mul\u001b[39m\u001b[38;5;124m\"\u001b[39m, maps_mul)\n\u001b[0;32m--> 902\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_frames\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatrices_mul\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaps_mul\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frames\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    908\u001b[0m     Graphs\u001b[38;5;241m.\u001b[39mextend([(create_graph(frames, typeEdge\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medges_residues\u001b[39m\u001b[38;5;124m\"\u001b[39m, comp_id\u001b[38;5;241m=\u001b[39mcomp_id), comp_id)])\n",
      "File \u001b[0;32m~/GithubProjects/pMHC_graph/utils/tools.py:1190\u001b[0m, in \u001b[0;36mgenerate_frames\u001b[0;34m(matrices, maps, debug, debug_every)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cn \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m checked_node_sets:\n\u001b[1;32m   1189\u001b[0m     checked_node_sets\u001b[38;5;241m.\u001b[39madd(cn)\n\u001b[0;32m-> 1190\u001b[0m     ok, es \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_subgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchosen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ok:\n\u001b[1;32m   1192\u001b[0m         \u001b[38;5;66;03m# chave canônica das arestas: pares (u<v), conjunto não-ordenado\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m         edge_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28msorted\u001b[39m(e)) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m es)\n",
      "File \u001b[0;32m~/GithubProjects/pMHC_graph/utils/tools.py:988\u001b[0m, in \u001b[0;36mgenerate_frames.<locals>.valid_subgraph\u001b[0;34m(nodes)\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# Verifica se todos os nós têm grau > 1\u001b[39;00m\n\u001b[0;32m--> 988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# Extrai as arestas do subgrafo: usamos apenas a parte triangular superior para evitar duplicatas\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ic_imuno311/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:2580\u001b[0m, in \u001b[0;36many\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_any_dispatcher)\n\u001b[1;32m   2478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21many\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;124;03m    Test whether any array element along a given axis evaluates to True.\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2578\u001b[0m \n\u001b[1;32m   2579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction_any_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_or\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43many\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2581\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ic_imuno311/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:102\u001b[0m, in \u001b[0;36m_wrapreduction_any_all\u001b[0;34m(obj, ufunc, method, axis, out, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res_both = run_cross_analysis(\n",
    "    mode=\"both\",\n",
    "    cross_df=crossDf,\n",
    "    manifest=manifest,\n",
    "    root=\"Analysis/CrossGraphs_10_CA_NewMethod\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Residue tracker for CrossSteps/<run_id> artifacts (read‑only)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "from __future__ import annotations\n",
    "import re, json, pickle\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple, Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Small loaders & format helpers\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _load_pickle(p: Path):\n",
    "    with open(p, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def _load_npy(p: Path) -> np.ndarray:\n",
    "    return np.load(p)\n",
    "\n",
    "def _sorted_run_files(run_dir: Path) -> List[Path]:\n",
    "    def key(p: Path):\n",
    "        m = re.match(r\"^(\\d{3})_\", p.name)\n",
    "        return int(m.group(1)) if m else 999999\n",
    "    return sorted([p for p in run_dir.iterdir() if p.is_file() and not p.name.startswith(\"_\")], key=key)\n",
    "\n",
    "def _parse_res_string(s: str) -> Tuple[str, str, str]:\n",
    "    # \"C:ASP:4\" -> (chain, resname, resnum_str)\n",
    "    ch, resname, resnum = s.split(\":\")\n",
    "    return ch, resname, str(resnum)\n",
    "\n",
    "def _idx_to_res_string(idx: int, residue_maps_unique: Dict[int, Tuple[str, str, str]]) -> str:\n",
    "    # residue_maps_unique[idx] = (chain, resnum_str, resname)\n",
    "    ch, resnum_str, resname = residue_maps_unique[idx]\n",
    "    return f\"{ch}:{resname}:{resnum_str}\"\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Reader for CrossSteps/<run_id> drops\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class RunReader:\n",
    "    \"\"\"\n",
    "    Minimal reader for a CrossSteps/<run_id> directory.\n",
    "    Only reads; never writes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, run_dir: str | Path):\n",
    "        self.base = Path(run_dir).resolve()\n",
    "        if not self.base.exists():\n",
    "            raise FileNotFoundError(self.base)\n",
    "        self.files = _sorted_run_files(self.base)\n",
    "\n",
    "        # index by \"short key\" (strip the NNN_ prefix and extension)\n",
    "        self.by_key: Dict[str, Path] = {}\n",
    "        for p in self.files:\n",
    "            stem = re.sub(r\"^\\d{3}_\", \"\", p.stem)\n",
    "            self.by_key[stem] = p\n",
    "\n",
    "        self._maps: Optional[Dict[str, Any]] = None\n",
    "        self._inv_maps: Optional[Dict[int, Dict[Tuple[str, str, str], int]]] = None\n",
    "        self._graph_collection: Optional[Dict[str, Any]] = None\n",
    "        self._cross_combos: Optional[Dict[Any, Any]] = None\n",
    "        self._graphs_bundle: Optional[Any] = None\n",
    "        self._dm_thresh: Optional[np.ndarray] = None\n",
    "        self._dm_prune: Optional[np.ndarray] = None\n",
    "\n",
    "    # core blobs ---------------------------------------------------------------\n",
    "\n",
    "    def maps(self) -> Dict[str, Any]:\n",
    "        if self._maps is None:\n",
    "            p = self.by_key.get(\"association_product_maps\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_maps.pkl not found\")\n",
    "            self._maps = _load_pickle(p)\n",
    "        return self._maps\n",
    "\n",
    "    def inv_maps(self) -> Dict[int, Dict[Tuple[str, str, str], int]]:\n",
    "        if self._inv_maps is None:\n",
    "            p = self.by_key.get(\"association_product_inv_maps\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_inv_maps.pkl not found\")\n",
    "            self._inv_maps = _load_pickle(p)\n",
    "        return self._inv_maps\n",
    "\n",
    "    def graph_collection(self) -> Dict[str, Any]:\n",
    "        if self._graph_collection is None:\n",
    "            p = self.by_key.get(\"association_product_graph_collection\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_graph_collection.pkl not found\")\n",
    "            self._graph_collection = _load_pickle(p)\n",
    "        return self._graph_collection\n",
    "\n",
    "    def cross_combos(self) -> Dict[Any, Any]:\n",
    "        if self._cross_combos is None:\n",
    "            p = self.by_key.get(\"association_product_cross_combos\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_cross_combos.pkl not found\")\n",
    "            self._cross_combos = _load_pickle(p)\n",
    "        return self._cross_combos\n",
    "\n",
    "    def graphs_bundle(self):\n",
    "        if self._graphs_bundle is None:\n",
    "            p = self.by_key.get(\"association_product_Graphs\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_Graphs.pkl not found\")\n",
    "            self._graphs_bundle = _load_pickle(p)\n",
    "        return self._graphs_bundle\n",
    "\n",
    "    def dm_thresholded(self) -> np.ndarray:\n",
    "        if self._dm_thresh is None:\n",
    "            p = self.by_key.get(\"association_product_dm_thresh\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_dm_thresh.npy not found\")\n",
    "            self._dm_thresh = _load_npy(p)\n",
    "        return self._dm_thresh\n",
    "\n",
    "    def dm_pruned(self) -> np.ndarray:\n",
    "        if self._dm_prune is None:\n",
    "            p = self.by_key.get(\"association_product_dm_prune\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_dm_prune.npy not found\")\n",
    "            self._dm_prune = _load_npy(p)\n",
    "        return self._dm_prune\n",
    "\n",
    "    # utilities ---------------------------------------------------------------\n",
    "\n",
    "    def list_components(self) -> List[int]:\n",
    "        return [comp_id for (_graphs, comp_id) in self.graphs_bundle()]\n",
    "\n",
    "    def components_with_nodes_indices(self) -> list[int]:\n",
    "        out = []\n",
    "        for cid in self.list_components():\n",
    "            if f\"comp_id_{cid}_nodes_indices\" in self.by_key:\n",
    "                out.append(cid)\n",
    "        return sorted(out)\n",
    "\n",
    "    def nodes_indices(self, comp_id: int) -> list[list[int]]:\n",
    "        key = f\"comp_id_{comp_id}_nodes_indices\"\n",
    "        p = self.by_key.get(key)\n",
    "        if p is None:\n",
    "            raise RuntimeError(\n",
    "                f\"{key}.pkl not found. comp_id_0 never has nodes_indices; use an id >= 1.\"\n",
    "            )\n",
    "        return _load_pickle(p)\n",
    "\n",
    "    def comp_matrices(self, comp_id: int) -> Dict[str, np.ndarray]:\n",
    "        key = f\"comp_id_{comp_id}_matrices_mul\"\n",
    "        p = self.by_key.get(key)\n",
    "        if p is None:\n",
    "            raise RuntimeError(f\"{key}.pkl not found\")\n",
    "        return _load_pickle(p)\n",
    "\n",
    "    def comp_maps(self, comp_id: int) -> Dict[str, Any]:\n",
    "        key = f\"comp_id_{comp_id}_maps_mul\"\n",
    "        p = self.by_key.get(key)\n",
    "        if p is None:\n",
    "            raise RuntimeError(f\"{key}.pkl not found\")\n",
    "        return _load_pickle(p)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Residue‑centric tracker\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class ResidueTracker:\n",
    "    \"\"\"\n",
    "    High‑level read‑only inspector for one or more residues.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reader: RunReader):\n",
    "        self.r = reader\n",
    "        self._maps = self.r.maps()\n",
    "        self._inv = self.r.inv_maps()\n",
    "        self._gc = self.r.graph_collection()\n",
    "        self._dmT = self.r.dm_thresholded()\n",
    "        self._dmP = self.r.dm_pruned()\n",
    "        self._runiq = self._maps[\"residue_maps_unique\"]  # global_index -> (chain, resnum_str, resname)\n",
    "        self._rfull = self._maps[\"full_residue_maps\"]    # per‑protein dicts: (chain,resnum,resname)->local\n",
    "\n",
    "    # ── presence & indices ───────────────────────────────────────────────────\n",
    "\n",
    "    def residue_indices(self, residue: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        For \"C:ASP:4\", report where it exists:\n",
    "          • protein index\n",
    "          • local index (within that protein graph order)\n",
    "          • global index (flattened across proteins; matches dm_* matrices)\n",
    "          • presence in the original per‑graph nodes\n",
    "        \"\"\"\n",
    "        ch, resname, resnum = _parse_res_string(residue)\n",
    "        triple = (ch, resnum, resname)  # shape used by maps\n",
    "\n",
    "        rows = []\n",
    "        offset = 0\n",
    "        # build offsets from residue_maps_unique_break (already made in pipeline)\n",
    "        uniq_break = self._maps.get(\"residue_maps_unique_break\")\n",
    "        # fallback: compute offsets from ranges_graph in metadata\n",
    "        ranges = self._maps.get(\"ranges_graph\") or self._gc.get(\"ranges_graph\") or {}\n",
    "\n",
    "        for p, local_map in enumerate(self._rfull):\n",
    "            present = triple in local_map\n",
    "            local_idx = local_map.get(triple, None)\n",
    "\n",
    "            if uniq_break and p in uniq_break:\n",
    "                gmap = uniq_break[p]\n",
    "                gidx = gmap.get(local_idx, None) if local_idx is not None else None\n",
    "            else:\n",
    "                # derive global by offset\n",
    "                if ranges and p in ranges:\n",
    "                    offset = ranges[p][0]\n",
    "                else:\n",
    "                    # compute offset by summing sizes up to p\n",
    "                    offset = sum(len(m) for m in self._rfull[:p])\n",
    "                gidx = (offset + local_idx) if local_idx is not None else None\n",
    "\n",
    "            in_graph_nodes = residue in set(self._gc[\"nodes_graphs\"][p])\n",
    "\n",
    "            rows.append({\n",
    "                \"residue\": residue,\n",
    "                \"protein\": p,\n",
    "                \"present\": bool(present),\n",
    "                \"local_index\": local_idx,\n",
    "                \"global_index\": gidx,\n",
    "                \"in_nodes_graph\": bool(in_graph_nodes),\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # ── node‑level extras: RSA, depth, coordinates (centroids) ───────────────\n",
    "\n",
    "    def residue_node_metrics(self, residue: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        For each protein where the residue exists, return:\n",
    "          • rsa value (if available)\n",
    "          • depth value (if available)\n",
    "          • centroid from the structure graph (if available)\n",
    "        \"\"\"\n",
    "        ch, resname, resnum = _parse_res_string(residue)\n",
    "        triple = (ch, resnum, resname)\n",
    "\n",
    "        rows = []\n",
    "        for p, local_map in enumerate(self._rfull):\n",
    "            if triple not in local_map:\n",
    "                continue\n",
    "            li = local_map[triple]\n",
    "\n",
    "            # RSA\n",
    "            rsa_val = None\n",
    "            try:\n",
    "                rsa_map: np.ndarray = self._gc[\"rsa_maps\"][p]\n",
    "                if isinstance(rsa_map, np.ndarray) and 0 <= li < rsa_map.shape[0]:\n",
    "                    rsa_val = float(rsa_map[li])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Depth\n",
    "            depth_val = None\n",
    "            try:\n",
    "                depths_list: List[np.ndarray] = self._gc.get(\"depths_maps\", [])\n",
    "                if p < len(depths_list):\n",
    "                    dvec = depths_list[p]\n",
    "                    if isinstance(dvec, np.ndarray) and 0 <= li < dvec.shape[0]:\n",
    "                        depth_val = float(dvec[li])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Coordinates / centroid if provided in graph.graph[\"coords\"]\n",
    "            coords = None\n",
    "            try:\n",
    "                G = self._gc[\"graphs\"][p]\n",
    "                label = residue  # node label is the \"A:GLU:154\" string\n",
    "                if label in G and \"x\" in G.nodes[label] and \"y\" in G.nodes[label] and \"z\" in G.nodes[label]:\n",
    "                    coords = (float(G.nodes[label][\"x\"]), float(G.nodes[label][\"y\"]), float(G.nodes[label][\"z\"]))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            rows.append({\n",
    "                \"residue\": residue,\n",
    "                \"protein\": p,\n",
    "                \"local_index\": li,\n",
    "                \"rsa\": rsa_val,\n",
    "                \"depth\": depth_val,\n",
    "                \"centroid_xyz\": coords,\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # ── DM hits (global space) ────────────────────────────────────────────────\n",
    "\n",
    "    def dm_neighbors(self, residue: str, *, matrix: str = \"thresholded\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Using global indices, list other residues that are in contact with this one\n",
    "        in the chosen global matrix (“thresholded” or “pruned”).\n",
    "        \"\"\"\n",
    "        pres = self.residue_indices(residue)\n",
    "        pres = pres[pres[\"global_index\"].notna()]\n",
    "        if pres.empty:\n",
    "            return pd.DataFrame(columns=[\"residue\", \"protein\", \"global_index\", \"neighbor_global\", \"neighbor_label\", \"dm_value\"])\n",
    "\n",
    "        M = self._dmT if matrix == \"thresholded\" else self._dmP\n",
    "        rows = []\n",
    "        for _, row in pres.iterrows():\n",
    "            gi = int(row[\"global_index\"])\n",
    "            vec = M[gi]\n",
    "            js = np.where(vec > 0)[0]\n",
    "            for j in js:\n",
    "                rows.append({\n",
    "                    \"residue\": residue,\n",
    "                    \"protein\": int(row[\"protein\"]),\n",
    "                    \"global_index\": gi,\n",
    "                    \"neighbor_global\": int(j),\n",
    "                    \"neighbor_label\": _idx_to_res_string(int(j), self._runiq),\n",
    "                    \"dm_value\": float(M[gi, j]),\n",
    "                })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # ── triads & cross‑combos participation ──────────────────────────────────\n",
    "\n",
    "    def triads_hits(self, residue: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        For each protein, lists tokens where the residue participates and the\n",
    "        matching triad tuples (triads_full) that contain it.\n",
    "        \"\"\"\n",
    "        out_rows = []\n",
    "        ch, resname, resnum = _parse_res_string(residue)\n",
    "        target = f\"{ch}:{resname}:{resnum}\"\n",
    "\n",
    "        triads_list = self._gc[\"triads\"]  # list[dict] per protein\n",
    "        for p, triads in enumerate(triads_list):\n",
    "            for token, payload in triads.items():\n",
    "                # payload: {\"count\": int, \"triads_full\": [triplet tuples …]}\n",
    "                hits = [tri for tri in payload.get(\"triads_full\", []) if target in tri[:3]]\n",
    "                if not hits:\n",
    "                    continue\n",
    "                out_rows.append({\n",
    "                    \"protein\": p,\n",
    "                    \"token\": token,\n",
    "                    \"n_hits\": len(hits),\n",
    "                    \"triads_full\": hits,\n",
    "                })\n",
    "        return pd.DataFrame(out_rows)\n",
    "\n",
    "    def cross_combos_hits(self, residue: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        In cross_combos (token → list of combinations), list combinations where\n",
    "        any per‑protein triad includes the residue in its first 3 elements.\n",
    "        \"\"\"\n",
    "        ch, resname, resnum = _parse_res_string(residue)\n",
    "        target = f\"{ch}:{resname}:{resnum}\"\n",
    "\n",
    "        cc = self.r.cross_combos()\n",
    "        rows = []\n",
    "        for token, combos in cc.items():\n",
    "            # combo is a tuple of triads (one triad per protein)\n",
    "            matches = []\n",
    "            for combo in combos:\n",
    "                if any(target in tri[:3] for tri in combo):\n",
    "                    matches.append(combo)\n",
    "            if matches:\n",
    "                rows.append({\n",
    "                    \"token\": token,\n",
    "                    \"n_combos\": len(matches),\n",
    "                    \"combos\": matches[:50],  # keep preview manageable\n",
    "                })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # ── components / frames participation ────────────────────────────────────\n",
    "\n",
    "    def components_frames(self, residue: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        For every component >= 1, and every frame graph inside it,\n",
    "        report whether the residue occurs in its node tuples and how many times.\n",
    "        \"\"\"\n",
    "        bundle = self.r.graphs_bundle()  # list of (list[nx.Graph], comp_id)\n",
    "        rows = []\n",
    "        for graphs, cid in bundle:\n",
    "            if cid == 0:\n",
    "                continue\n",
    "            for frame_id, G in enumerate(graphs):\n",
    "                if not isinstance(G, nx.Graph):\n",
    "                    continue\n",
    "                count = 0\n",
    "                for node in G.nodes():\n",
    "                    # node is a tuple of residue strings (one per protein)\n",
    "                    if isinstance(node, tuple) and any(str(residue) == str(x) for x in node):\n",
    "                        count += 1\n",
    "                if count:\n",
    "                    rows.append({\"component\": cid, \"frame\": frame_id, \"occurrences\": count})\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # ── variation context in component matrices ──────────────────────────────\n",
    "\n",
    "    def component_variation_context(self, residue: str) -> Dict[int, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        For each component that has matrices_mul/maps_mul:\n",
    "          • rows in maps_mul['possible_nodes'] where the residue's global index appears\n",
    "          • the corresponding rows/cols from dm_possible_nodes and adj_possible_nodes\n",
    "        Returns comp_id → {\"rows\": [...], \"dm_slices\": [...], \"adj_slices\": [...]}\n",
    "        \"\"\"\n",
    "        # collect all global indices this residue maps to (one per protein)\n",
    "        pres = self.residue_indices(residue)\n",
    "        gidxs = [int(x) for x in pres[\"global_index\"].dropna().unique().tolist()]\n",
    "\n",
    "        out: Dict[int, Dict[str, Any]] = {}\n",
    "        for cid in self.r.components_with_nodes_indices():\n",
    "            mats = self.r.comp_matrices(cid)   # {\"dm_possible_nodes\", \"adj_possible_nodes\"}\n",
    "            cmap = self.r.comp_maps(cid)       # contains \"possible_nodes\": {row_idx -> [glob_i_per_protein]}\n",
    "\n",
    "            poss = cmap.get(\"possible_nodes\", {})\n",
    "            # normalize to dict[int]->list[int]\n",
    "            norm_poss = {}\n",
    "            for k, v in poss.items():\n",
    "                key = int(k) if not isinstance(k, int) else k\n",
    "                vv = list(v) if isinstance(v, (list, tuple, np.ndarray)) else [int(v)]\n",
    "                norm_poss[key] = [int(x) for x in vv]\n",
    "\n",
    "            # rows where any of the residue's global indices appear\n",
    "            hits = []\n",
    "            for row_idx, glob_list in norm_poss.items():\n",
    "                if any(g == h for g in gidxs for h in glob_list):\n",
    "                    hits.append((int(row_idx), glob_list))\n",
    "\n",
    "            if not hits:\n",
    "                continue\n",
    "\n",
    "            dm = mats[\"dm_possible_nodes\"]\n",
    "            adj = mats[\"adj_possible_nodes\"]\n",
    "\n",
    "            dm_slices, adj_slices = [], []\n",
    "            for row_idx, _ in hits:\n",
    "                dm_slices.append(dm[row_idx, :])\n",
    "                adj_slices.append(adj[row_idx, :])\n",
    "\n",
    "            out[cid] = {\n",
    "                \"rows\": hits,\n",
    "                \"dm_rows\": dm_slices,\n",
    "                \"adj_rows\": adj_slices,\n",
    "            }\n",
    "        return out\n",
    "\n",
    "    # ── one‑shot convenience ─────────────────────────────────────────────────\n",
    "\n",
    "    def track_one(self, residue: str) -> Dict[str, Any]:\n",
    "        pres   = self.residue_indices(residue)\n",
    "        node   = self.residue_node_metrics(residue)\n",
    "        triads = self.triads_hits(residue)\n",
    "        combos = self.cross_combos_hits(residue)\n",
    "        frames = self.components_frames(residue)\n",
    "        varctx = self.component_variation_context(residue)\n",
    "        return {\n",
    "            \"presence\": pres,\n",
    "            \"node_metrics\": node,\n",
    "            \"triads_df\": triads,\n",
    "            \"cross_combos_df\": combos,\n",
    "            \"frames_df\": frames,\n",
    "            \"variation_context\": varctx,\n",
    "        }\n",
    "\n",
    "    def track_batch(self, residues: Iterable[str]) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        for r in residues:\n",
    "            d = self.track_one(r)\n",
    "            # quick overview row\n",
    "            rows.append({\n",
    "                \"residue\": r,\n",
    "                \"proteins_found\": d[\"presence\"][\"present\"].sum(),\n",
    "                \"in_frames\": int(d[\"frames_df\"][\"occurrences\"].sum()) if not d[\"frames_df\"].empty else 0,\n",
    "                \"n_triads_hits\": int(d[\"triads_df\"][\"n_hits\"].sum()) if not d[\"triads_df\"].empty else 0,\n",
    "                \"n_cross_combos\": int(d[\"cross_combos_df\"][\"n_combos\"].sum()) if not d[\"cross_combos_df\"].empty else 0,\n",
    "            })\n",
    "        return pd.DataFrame(rows).sort_values([\"proteins_found\", \"in_frames\", \"n_cross_combos\", \"n_triads_hits\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc79bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Residue tracking over CrossSteps artifacts — read‑only (no writes)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "from __future__ import annotations\n",
    "import re, json, pickle\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple, Iterable, Optional\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Basic loaders\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _load_pickle(p: Path):\n",
    "    with open(p, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def _load_npy(p: Path) -> np.ndarray:\n",
    "    return np.load(p)\n",
    "\n",
    "def _sorted_run_files(run_dir: Path) -> List[Path]:\n",
    "    def key(p: Path):\n",
    "        m = re.match(r\"^(\\d{3})_\", p.name)\n",
    "        return int(m.group(1)) if m else 999999\n",
    "    return sorted([p for p in run_dir.iterdir() if p.is_file()], key=key)\n",
    "\n",
    "def _idx_to_res_string(idx: int, residue_maps_unique: Dict[int, Tuple[str, str, str]]) -> str:\n",
    "    ch, resnum_str, resname = residue_maps_unique[idx]\n",
    "    return f\"{ch}:{resname}:{resnum_str}\"\n",
    "\n",
    "def _res_string_to_tuple(s: str) -> Tuple[str,str,str]:\n",
    "    ch, resname, resnum = s.split(\":\")\n",
    "    return (ch, resnum, resname)  # your inv_maps key order\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# RunReader: read only from CrossSteps/<run_id>\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class RunReader:\n",
    "    \"\"\"\n",
    "    Thin reader for a CrossSteps/<run_id> directory.\n",
    "    It builds a quick index (\"by_key\") using filenames without the numeric prefix.\n",
    "    \"\"\"\n",
    "    def __init__(self, run_dir: str | Path):\n",
    "        self.base = Path(run_dir).resolve()\n",
    "        if not self.base.exists():\n",
    "            raise FileNotFoundError(self.base)\n",
    "        self.files = _sorted_run_files(self.base)\n",
    "\n",
    "        self.by_key: Dict[str, Path] = {}\n",
    "        for p in self.files:\n",
    "            stem = re.sub(r\"^\\d{3}_\", \"\", p.stem)\n",
    "            self.by_key[stem] = p\n",
    "\n",
    "        self._maps: Optional[Dict[str, Any]] = None\n",
    "        self._inv_maps: Optional[Dict[int, Dict[Tuple[str,str,str], int]]] = None\n",
    "        self._gc: Optional[Dict[str, Any]] = None\n",
    "        self._graphs_bundle: Optional[Any] = None\n",
    "        self._dm_thresh: Optional[np.ndarray] = None\n",
    "        self._dm_prune: Optional[np.ndarray] = None\n",
    "\n",
    "    def meta(self) -> Dict[str, Any]:\n",
    "        p = self.base / \"_meta.json\"\n",
    "        return json.loads(p.read_text()) if p.exists() else {}\n",
    "\n",
    "    def maps(self) -> Dict[str, Any]:\n",
    "        if self._maps is None:\n",
    "            p = self.by_key.get(\"association_product_maps\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_maps.pkl not found\")\n",
    "            self._maps = _load_pickle(p)\n",
    "        return self._maps\n",
    "\n",
    "    def inv_maps(self) -> Dict[int, Dict[Tuple[str,str,str], int]]:\n",
    "        if self._inv_maps is None:\n",
    "            p = self.by_key.get(\"association_product_inv_maps\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_inv_maps.pkl not found\")\n",
    "            self._inv_maps = _load_pickle(p)\n",
    "        return self._inv_maps\n",
    "\n",
    "    def graph_collection(self) -> Dict[str, Any]:\n",
    "        if self._gc is None:\n",
    "            p = self.by_key.get(\"association_product_graph_collection\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_graph_collection.pkl not found\")\n",
    "            self._gc = _load_pickle(p)\n",
    "        return self._gc\n",
    "\n",
    "    def cross_combos(self) -> Dict[Any, Any]:\n",
    "        p = self.by_key.get(\"association_product_cross_combos\")\n",
    "        return _load_pickle(p) if p else {}\n",
    "\n",
    "    def triad_graph_edges(self) -> Optional[set]:\n",
    "        p = self.by_key.get(\"association_product_triad_graph\")\n",
    "        return _load_pickle(p) if p else None\n",
    "\n",
    "    def graphs_bundle(self):\n",
    "        if self._graphs_bundle is None:\n",
    "            p = self.by_key.get(\"association_product_Graphs\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_Graphs.pkl not found\")\n",
    "            self._graphs_bundle = _load_pickle(p)\n",
    "        return self._graphs_bundle\n",
    "\n",
    "    def dm_thresh(self) -> np.ndarray:\n",
    "        if self._dm_thresh is None:\n",
    "            p = self.by_key.get(\"association_product_dm_thresh\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_dm_thresh.npy not found\")\n",
    "            self._dm_thresh = _load_npy(p)\n",
    "        return self._dm_thresh\n",
    "\n",
    "    def dm_prune(self) -> np.ndarray:\n",
    "        if self._dm_prune is None:\n",
    "            p = self.by_key.get(\"association_product_dm_prune\")\n",
    "            if p is None:\n",
    "                raise RuntimeError(\"association_product_dm_prune.npy not found\")\n",
    "            self._dm_prune = _load_npy(p)\n",
    "        return self._dm_prune\n",
    "\n",
    "    def components(self) -> List[int]:\n",
    "        \"\"\"\n",
    "        Return sorted component IDs that have per‑component artifacts.\n",
    "        comp_id_0 is the \"base\" and intentionally has no nodes_indices/matrices_mul.\n",
    "        \"\"\"\n",
    "        out = set()\n",
    "        for k in self.by_key:\n",
    "            m = re.match(r\"comp_id_(\\d+)_\", k)\n",
    "            if m:\n",
    "                out.add(int(m.group(1)))\n",
    "        return sorted(out)\n",
    "\n",
    "    # Per‑component helpers (skip comp_id_0 for nodes_indices / matrices_mul)\n",
    "    def comp_nodes_indices(self, comp_id: int) -> Optional[List[List[int]]]:\n",
    "        p = self.by_key.get(f\"comp_id_{comp_id}_nodes_indices\")\n",
    "        return _load_pickle(p) if p else None\n",
    "\n",
    "    def comp_matrices_mul(self, comp_id: int) -> Optional[Dict[str, np.ndarray]]:\n",
    "        p = self.by_key.get(f\"comp_id_{comp_id}_matrices_mul\")\n",
    "        return _load_pickle(p) if p else None\n",
    "\n",
    "    def comp_maps_mul(self, comp_id: int) -> Optional[Dict[str, Any]]:\n",
    "        p = self.by_key.get(f\"comp_id_{comp_id}_maps_mul\")\n",
    "        return _load_pickle(p) if p else None\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# ResidueTracker: read-only analytics for one or many residues\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class ResidueTracker:\n",
    "    \"\"\"\n",
    "    Track a residue like 'C:ASP:4' across:\n",
    "      • presence in each source graph\n",
    "      • global index (inv_maps)\n",
    "      • contact-map distances (dm_thresh/dm_prune) against all residues\n",
    "      • RSA per source graph\n",
    "      • component+frame appearances (association_product_Graphs)\n",
    "      • variation context from per-component matrices (dm_possible_nodes/adj_possible_nodes)\n",
    "      • combo/triad hits (cross_combos)\n",
    "    \"\"\"\n",
    "    def __init__(self, reader: RunReader):\n",
    "        self.r = reader\n",
    "        self._maps = self.r.maps()\n",
    "        self._inv = self.r.inv_maps()\n",
    "        self._gc   = self.r.graph_collection()\n",
    "        self._rmap_unique: Dict[int, Tuple[str,str,str]] = self._maps[\"residue_maps_unique\"]  # global→(chain,resnum,resname)\n",
    "\n",
    "        # quick \"residue string\" sets per protein graph\n",
    "        self._nodes_per_graph: List[List[str]] = self._gc[\"nodes_graphs\"]\n",
    "\n",
    "        # RSA arrays per graph (in same node order as nodes_graphs)\n",
    "        self._rsa_maps: List[np.ndarray] = self._gc[\"rsa_maps\"]\n",
    "\n",
    "        # contact maps per graph (already embedded globally in dm_* via indices + ranges)\n",
    "        self._ranges = self._maps[\"ranges_graph\"] if \"ranges_graph\" in self._maps else self._infer_ranges()\n",
    "\n",
    "    def _infer_ranges(self) -> List[Tuple[int,int]]:\n",
    "        # Fallback if ranges weren't persisted inside maps (you do persist in metadata)\n",
    "        # Use metadata from matrices_dict in your pipeline if present; otherwise derive from nodes_graphs lengths\n",
    "        sizes = [len(nodes) for nodes in self._nodes_per_graph]\n",
    "        out, cur = [], 0\n",
    "        for n in sizes:\n",
    "            out.append((cur, cur+n))\n",
    "            cur += n\n",
    "        return out\n",
    "\n",
    "    def _resolve(self, residue: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Map 'C:ASP:4' to:\n",
    "          • per‑protein index (if present)\n",
    "          • global index (via inv_maps[k])\n",
    "        \"\"\"\n",
    "        tup = _res_string_to_tuple(residue)\n",
    "        per_protein_idx = {}\n",
    "        global_idx = {}\n",
    "        for k, inv in self._inv.items():\n",
    "            g = inv.get(tup)\n",
    "            if g is not None:\n",
    "                global_idx[k] = g\n",
    "        # Also tell whether it’s present in the original node set for each protein:\n",
    "        present = {}\n",
    "        for k, nodes in enumerate(self._nodes_per_graph):\n",
    "            present[k] = residue in nodes\n",
    "            if present[k]:\n",
    "                per_protein_idx[k] = nodes.index(residue)\n",
    "        return {\"tuple\": tup, \"per_protein_idx\": per_protein_idx, \"global_idx\": global_idx, \"present\": present}\n",
    "\n",
    "    # — Presence, RSA, distances (global matrix views) --------------------------------\n",
    "\n",
    "    def presence_table(self, residue: str) -> pd.DataFrame:\n",
    "        res = self._resolve(residue)\n",
    "        rows = []\n",
    "        for k in range(len(self._nodes_per_graph)):\n",
    "            rows.append({\n",
    "                \"residue\": residue,\n",
    "                \"protein\": k,\n",
    "                \"present\": bool(res[\"present\"].get(k, False)),\n",
    "                \"global_index\": res[\"global_idx\"].get(k, np.nan),\n",
    "                \"per_protein_index\": res[\"per_protein_idx\"].get(k, np.nan),\n",
    "            })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def rsa_rows(self, residue: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return RSA values for the residue in each source protein (if present).\n",
    "        \"\"\"\n",
    "        res = self._resolve(residue)\n",
    "        out = []\n",
    "        for k, nodes in enumerate(self._nodes_per_graph):\n",
    "            if residue in nodes:\n",
    "                idx = nodes.index(residue)\n",
    "                rsa = float(self._rsa_maps[k][idx])\n",
    "                out.append({\"protein\": k, \"residue\": residue, \"rsa\": rsa})\n",
    "        return pd.DataFrame(out)\n",
    "\n",
    "    def distances_rows(self, residue: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Use global dm_thresh / dm_prune as a full distance lookup against every residue.\n",
    "        Rows are (protein, other_residue, dm_thresh, dm_prune). NaNs are preserved.\n",
    "        \"\"\"\n",
    "        dmT = self.r.dm_thresh()\n",
    "        dmP = self.r.dm_prune()\n",
    "        res = self._resolve(residue)\n",
    "        rows = []\n",
    "\n",
    "        if not res[\"global_idx\"]:\n",
    "            return pd.DataFrame(columns=[\"protein\",\"residue\",\"other_residue\",\"dm_thresh\",\"dm_prune\"])\n",
    "\n",
    "        for k, g_idx in res[\"global_idx\"].items():\n",
    "            start, end = self._ranges[k]\n",
    "            for other_g in range(start, end):\n",
    "                other_res = _idx_to_res_string(other_g, self._rmap_unique)\n",
    "                rows.append({\n",
    "                    \"protein\": k,\n",
    "                    \"residue\": residue,\n",
    "                    \"other_residue\": other_res,\n",
    "                    \"dm_thresh\": dmT[g_idx, other_g],\n",
    "                    \"dm_prune\":  dmP[g_idx, other_g],\n",
    "                })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # — Combo / Triad hits ------------------------------------------------------\n",
    "\n",
    "    def triad_combo_hits(self, residue: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Scan cross_combos for any triad where residue appears.\n",
    "        Each combo is a tuple of triads (one per protein):\n",
    "           tri = (r1, r2, r3, ..., distances...)\n",
    "        We check tri[:3] only for residue membership.\n",
    "        \"\"\"\n",
    "        cc = self.r.cross_combos()\n",
    "\n",
    "        if not cc:\n",
    "            return pd.DataFrame(columns=[\"token\",\"combo_idx\",\"protein\",\"triad_3res\"])\n",
    "\n",
    "        res_hits = []\n",
    "        target = residue\n",
    "        for token, combos in cc.items():\n",
    "            for ci, combo in enumerate(combos):\n",
    "                for pi, tri in enumerate(combo):\n",
    "                    tri3 = tri[:3]\n",
    "                    if target in tri3:\n",
    "                        res_hits.append({\n",
    "                            \"token\": token,\n",
    "                            \"combo_idx\": ci,\n",
    "                            \"protein\": pi,\n",
    "                            \"triad_3res\": tri3\n",
    "                        })\n",
    "        return pd.DataFrame(res_hits)\n",
    "\n",
    "    # — Frames / Associated graphs ---------------------------------------------\n",
    "\n",
    "    def frames_rows(self, residue: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Find all (component, frame) graph nodes containing this residue.\n",
    "        Nodes in the final graphs are residue tuples (one per protein).\n",
    "        \"\"\"\n",
    "        bundle = self.r.graphs_bundle()   # list of (list[nx.Graph], comp_id)\n",
    "        rows = []\n",
    "        for graphs, comp_id in bundle:\n",
    "            # comp_id_0 is the base combo graph; its nodes are usually not residue tuples for frames\n",
    "            for frame_id, G in enumerate(graphs):\n",
    "                for node in G.nodes():\n",
    "                    if isinstance(node, tuple) and any(\n",
    "                        (isinstance(x, str) and x == residue) for x in node\n",
    "                    ):\n",
    "                        rows.append({\"component\": comp_id, \"frame\": frame_id, \"node\": node})\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    # — Variation context from per-component matrices --------------------------\n",
    "\n",
    "    def _component_possibles_for_residue(self, comp_id: int, residue: str) -> List[Tuple[int, List[int]]]:\n",
    "        \"\"\"\n",
    "        For comp_id>=1, find rows in maps_mul['possible_nodes'] that include the residue’s global index (per protein).\n",
    "        Returns list of (row_idx, [global_idx_per_protein]).\n",
    "        \"\"\"\n",
    "        maps_mul = self.r.comp_maps_mul(comp_id)\n",
    "        if not maps_mul:\n",
    "            return []\n",
    "        poss = maps_mul.get(\"possible_nodes\", {})\n",
    "        res = self._resolve(residue)\n",
    "        gidxs = [res[\"global_idx\"].get(p) for p in sorted(res[\"global_idx\"].keys())]\n",
    "        gidxs = [g for g in gidxs if g is not None]\n",
    "        if not gidxs:\n",
    "            return []\n",
    "\n",
    "        hits = []\n",
    "        for row_idx, glob_list in poss.items():\n",
    "            # poss values are lists of global indices for that candidate node\n",
    "            if isinstance(glob_list, list) and any(g in glob_list for g in gidxs):\n",
    "                hits.append((int(row_idx), list(map(int, glob_list))))\n",
    "        return hits\n",
    "\n",
    "    def variation_context(self, residue: str) -> Dict[int, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        For each comp_id>=1, return:\n",
    "          • rows in possible_nodes that contain the residue\n",
    "          • dm_possible_nodes and adj_possible_nodes (the per‑component “variation matrices”)\n",
    "        \"\"\"\n",
    "        out: Dict[int, Dict[str, Any]] = {}\n",
    "        for comp_id in self.r.components():\n",
    "            if comp_id == 0:\n",
    "                continue\n",
    "            matrices = self.r.comp_matrices_mul(comp_id) or {}\n",
    "            ctx_rows = self._component_possibles_for_residue(comp_id, residue)\n",
    "            out[comp_id] = {\n",
    "                \"possible_rows_hit\": ctx_rows,  # list[(row_idx, [global idx list])]\n",
    "                \"dm_possible_nodes_shape\": tuple(matrices.get(\"dm_possible_nodes\", np.empty((0,))).shape),\n",
    "                \"adj_possible_nodes_shape\": tuple(matrices.get(\"adj_possible_nodes\", np.empty((0,))).shape),\n",
    "            }\n",
    "        return out\n",
    "\n",
    "    # — One-call report ---------------------------------------------------------\n",
    "\n",
    "    def track_one(self, residue: str) -> Dict[str, Any]:\n",
    "        pres  = self.presence_table(residue)\n",
    "        rsa   = self.rsa_rows(residue)\n",
    "        dist  = self.distances_rows(residue)\n",
    "        frames= self.frames_rows(residue)\n",
    "        combos= self.triad_combo_hits(residue)\n",
    "        varcx = self.variation_context(residue)\n",
    "\n",
    "        partners = []\n",
    "        for k in range(len(self._nodes_per_graph)):\n",
    "            dfk = dist[dist[\"protein\"]==k].copy()\n",
    "            if not dfk.empty:\n",
    "                # mark as contact if dm_thresh is finite and >0 (your pipeline uses 0/NaN for “no edge”)\n",
    "                mask = (~dfk[\"dm_thresh\"].isna()) & (dfk[\"dm_thresh\"]>0)\n",
    "                counts = dfk.loc[mask, \"other_residue\"].value_counts()\n",
    "                partners.append(pd.DataFrame({\n",
    "                    \"protein\": k,\n",
    "                    \"partner\": counts.index,\n",
    "                    \"count_thresh_contact\": counts.values\n",
    "                }))\n",
    "        partners_df = pd.concat(partners, ignore_index=True) if partners else pd.DataFrame(columns=[\"protein\",\"partner\",\"count_thresh_contact\"])\n",
    "\n",
    "        return {\n",
    "            \"presence\": pres,                    # per source graph presence/global idx\n",
    "            \"rsa\": rsa,                          # RSA per protein (if present)\n",
    "            \"distances\": dist,                   # dm_thresh/dm_prune rows against all residues in that protein\n",
    "            \"frames\": frames,                    # where it appears in final graphs\n",
    "            \"combos\": combos,                    # cross_combos occurrences\n",
    "            \"variation_context\": varcx,          # shapes + rows hit in per‑component matrices\n",
    "            \"partners_summary\": partners_df,     # quick contact counts\n",
    "        }\n",
    "\n",
    "    # — Batch ---------------------------------------------------------------\n",
    "\n",
    "    def track_many(self, residues: Iterable[str]) -> Dict[str, Dict[str, Any]]:\n",
    "        return {r: self.track_one(r) for r in residues}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Example usage (Jupyter)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Point to a finished run directory (must contain the association_product_* files)\n",
    "RUN_DIR = \"CrossSteps/3tjh_3tfk\"    # <- change to your run folder\n",
    "rr = RunReader(RUN_DIR)\n",
    "rt = ResidueTracker(rr)\n",
    "\n",
    "# Single residue\n",
    "res = \"A:VAL:66\"\n",
    "out = rt.track_one(res)\n",
    "display(out[\"presence\"])\n",
    "display(out[\"rsa\"].head())\n",
    "display(out[\"distances\"].head())\n",
    "display(out[\"frames\"].head())\n",
    "display(out[\"combos\"].head())\n",
    "print(out[\"variation_context\"])\n",
    "display(out[\"partners_summary\"].head())\n",
    "\n",
    "# Many residues\n",
    "# targets = [\"A:ALA:45\", \"C:GLU:2\", \"C:ASP:4\"]\n",
    "# bundle = rt.track_many(targets)\n",
    "# # to peek one of them:\n",
    "# display(bundle[\"A:ALA:45\"][\"presence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {('ALA', 'GLU', 'GLY', 0, 0, 0, 2, 2, 2, 3, 3, 2): [(('A:ALA:158', 'A:GLU:161', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 3, 2), ('A:ALA:158', 'A:GLU:161', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 3, 2)), (('A:ALA:158', 'A:GLU:163', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 3, 2), ('A:ALA:158', 'A:GLU:161', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 3, 2))], ('GLY', 'GLU', 'TYR', 0, 0, 0, 1, 2, 2, 2, 3, 2): [(('A:GLY:151', 'A:GLU:154', 'A:TYR:155', 0, 0, 0, 1, 2, 2, 2, 3, 2), ('A:GLY:151', 'A:GLU:154', 'A:TYR:155', 0, 0, 0, 1, 2, 2, 2, 3, 2))], ('GLU', 'VAL', 'TRP', 0, 0, 0, 2, 1, 1, 3, 5, 3): [(('A:GLU:161', 'A:VAL:165', 'A:TRP:167', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:GLU:161', 'A:VAL:165', 'A:TRP:167', 0, 0, 0, 2, 1, 1, 3, 5, 3))], ('ARG', 'ALA', 'TYR', 0, 0, 0, 1, 2, 2, 2, 3, 3): [(('A:ARG:157', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 1, 2, 2, 2, 3, 3), ('A:ARG:157', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 1, 2, 2, 2, 3, 3))], ('GLN', 'ARG', 'GLU', 0, 0, 0, 2, 1, 1, 3, 4, 3): [(('A:GLN:65', 'A:ARG:62', 'A:GLU:58', 0, 0, 0, 2, 1, 1, 3, 4, 3), ('A:GLN:72', 'A:ARG:75', 'A:GLU:19', 0, 0, 0, 2, 1, 1, 3, 4, 3))], ('ARG', 'THR', 'VAL', 0, 0, 0, 2, 1, 1, 2, 3, 3): [(('A:ARG:79', 'A:THR:80', 'A:VAL:76', 0, 0, 0, 2, 1, 1, 2, 3, 3), ('A:ARG:79', 'A:THR:80', 'A:VAL:76', 0, 0, 0, 2, 1, 1, 2, 3, 3))], ('ARG', 'VAL', 'GLU', 0, 0, 0, 2, 1, 1, 3, 5, 2): [(('A:ARG:108', 'A:VAL:165', 'A:GLU:166', 0, 0, 0, 2, 1, 1, 3, 5, 2), ('A:ARG:108', 'A:VAL:165', 'A:GLU:166', 0, 0, 0, 2, 1, 1, 3, 5, 2))], ('ARG', 'GLU', 'GLY', 0, 0, 0, 1, 2, 2, 3, 4, 2): [(('A:ARG:157', 'A:GLU:161', 'A:GLY:162', 0, 0, 0, 1, 2, 2, 3, 4, 2), ('A:ARG:157', 'A:GLU:161', 'A:GLY:162', 0, 0, 0, 1, 2, 2, 3, 4, 2)), (('A:ARG:157', 'A:GLU:161', 'A:GLY:162', 0, 0, 0, 1, 2, 2, 3, 4, 2), ('A:ARG:75', 'A:GLU:19', 'A:GLY:18', 0, 0, 0, 1, 2, 2, 3, 4, 2)), (('A:ARG:157', 'A:GLU:154', 'A:GLY:151', 0, 0, 0, 1, 2, 2, 3, 4, 2), ('A:ARG:157', 'A:GLU:161', 'A:GLY:162', 0, 0, 0, 1, 2, 2, 3, 4, 2)), (('A:ARG:157', 'A:GLU:154', 'A:GLY:151', 0, 0, 0, 1, 2, 2, 3, 4, 2), ('A:ARG:75', 'A:GLU:19', 'A:GLY:18', 0, 0, 0, 1, 2, 2, 3, 4, 2)), (('A:ARG:75', 'A:GLU:19', 'A:GLY:18', 0, 0, 0, 1, 2, 2, 3, 4, 2), ('A:ARG:157', 'A:GLU:161', 'A:GLY:162', 0, 0, 0, 1, 2, 2, 3, 4, 2)), (('A:ARG:75', 'A:GLU:19', 'A:GLY:18', 0, 0, 0, 1, 2, 2, 3, 4, 2), ('A:ARG:75', 'A:GLU:19', 'A:GLY:18', 0, 0, 0, 1, 2, 2, 3, 4, 2))], ('TRP', 'GLU', 'VAL', 0, 0, 0, 1, 2, 2, 2, 3, 2): [(('A:TRP:167', 'A:GLU:166', 'A:VAL:165', 0, 0, 0, 1, 2, 2, 2, 3, 2), ('A:TRP:167', 'A:GLU:166', 'A:VAL:165', 0, 0, 0, 1, 2, 2, 2, 3, 2))], ('GLU', 'TRP', 'VAL', 0, 0, 0, 2, 1, 1, 2, 2, 3): [(('A:GLU:166', 'A:TRP:167', 'A:VAL:165', 0, 0, 0, 2, 1, 1, 2, 2, 3), ('A:GLU:166', 'A:TRP:167', 'A:VAL:165', 0, 0, 0, 2, 1, 1, 2, 2, 3))], ('ARG', 'VAL', 'GLU', 0, 0, 0, 2, 1, 1, 3, 4, 3): [(('A:ARG:108', 'A:VAL:165', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 3, 4, 3), ('A:ARG:108', 'A:VAL:165', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 3, 4, 3))], ('ALA', 'GLU', 'ARG', 0, 0, 0, 2, 2, 2, 3, 2, 3): [(('A:ALA:158', 'A:GLU:161', 'A:ARG:157', 0, 0, 0, 2, 2, 2, 3, 2, 3), ('A:ALA:158', 'A:GLU:161', 'A:ARG:157', 0, 0, 0, 2, 2, 2, 3, 2, 3)), (('A:ALA:158', 'A:GLU:154', 'A:ARG:157', 0, 0, 0, 2, 2, 2, 3, 2, 3), ('A:ALA:158', 'A:GLU:161', 'A:ARG:157', 0, 0, 0, 2, 2, 2, 3, 2, 3))], ('ALA', 'GLU', 'GLY', 0, 0, 0, 2, 2, 2, 3, 4, 2): [(('A:ALA:158', 'A:GLU:154', 'A:GLY:151', 0, 0, 0, 2, 2, 2, 3, 4, 2), ('A:ALA:158', 'A:GLU:154', 'A:GLY:151', 0, 0, 0, 2, 2, 2, 3, 4, 2))], ('GLN', 'GLU', 'LYS', 0, 0, 0, 2, 1, 1, 2, 3, 3): [(('A:GLN:72', 'A:GLU:71', 'A:LYS:68', 0, 0, 0, 2, 1, 1, 2, 3, 3), ('A:GLN:72', 'A:GLU:71', 'A:LYS:68', 0, 0, 0, 2, 1, 1, 2, 3, 3))], ('ARG', 'VAL', 'GLU', 0, 0, 0, 2, 1, 1, 3, 6, 3): [(('A:ARG:108', 'A:VAL:165', 'A:GLU:163', 0, 0, 0, 2, 1, 1, 3, 6, 3), ('A:ARG:108', 'A:VAL:165', 'A:GLU:163', 0, 0, 0, 2, 1, 1, 3, 6, 3))], ('GLY', 'GLN', 'LYS', 0, 0, 0, 1, 2, 2, 2, 2, 3): [(('A:GLY:69', 'A:GLN:72', 'A:LYS:68', 0, 0, 0, 1, 2, 2, 2, 2, 3), ('A:GLY:69', 'A:GLN:72', 'A:LYS:68', 0, 0, 0, 1, 2, 2, 2, 2, 3))], ('ARG', 'ILE', 'LYS', 0, 0, 0, 1, 1, 1, 3, 3, 3): [(('A:ARG:144', 'A:ILE:142', 'A:LYS:146', 0, 0, 0, 1, 1, 1, 3, 3, 3), ('A:ARG:144', 'A:ILE:142', 'A:LYS:146', 0, 0, 0, 1, 1, 1, 3, 3, 3))], ('GLU', 'TYR', 'GLY', 0, 0, 0, 2, 1, 1, 2, 2, 3): [(('A:GLU:154', 'A:TYR:155', 'A:GLY:151', 0, 0, 0, 2, 1, 1, 2, 2, 3), ('A:GLU:154', 'A:TYR:155', 'A:GLY:151', 0, 0, 0, 2, 1, 1, 2, 2, 3))], ('ALA', 'GLY', 'GLU', 0, 0, 0, 2, 1, 1, 3, 3, 2): [(('A:ALA:158', 'A:GLY:162', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 3, 3, 2), ('A:ALA:158', 'A:GLY:162', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 3, 3, 2)), (('A:ALA:158', 'A:GLY:162', 'A:GLU:163', 0, 0, 0, 2, 1, 1, 3, 3, 2), ('A:ALA:158', 'A:GLY:162', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 3, 3, 2))], ('ALA', 'ARG', 'GLU', 0, 0, 0, 2, 1, 1, 2, 3, 3): [(('A:ALA:158', 'A:ARG:157', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 2, 3, 3), ('A:ALA:158', 'A:ARG:157', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 2, 3, 3)), (('A:ALA:158', 'A:ARG:157', 'A:GLU:154', 0, 0, 0, 2, 1, 1, 2, 3, 3), ('A:ALA:158', 'A:ARG:157', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 2, 3, 3))], ('ALA', 'GLU', 'VAL', 0, 0, 0, 2, 2, 2, 3, 5, 3): [(('A:ALA:158', 'A:GLU:161', 'A:VAL:165', 0, 0, 0, 2, 2, 2, 3, 5, 3), ('A:ALA:158', 'A:GLU:161', 'A:VAL:165', 0, 0, 0, 2, 2, 2, 3, 5, 3)), (('A:ALA:158', 'A:GLU:163', 'A:VAL:165', 0, 0, 0, 2, 2, 2, 3, 5, 3), ('A:ALA:158', 'A:GLU:161', 'A:VAL:165', 0, 0, 0, 2, 2, 2, 3, 5, 3))], ('ARG', 'ARG', 'VAL', 0, 0, 0, 2, 1, 1, 3, 3, 2): [(('A:ARG:79', 'A:ARG:75', 'A:VAL:76', 0, 0, 0, 2, 1, 1, 3, 3, 2), ('A:ARG:79', 'A:ARG:75', 'A:VAL:76', 0, 0, 0, 2, 1, 1, 3, 3, 2))], ('GLU', 'ALA', 'TYR', 0, 0, 0, 2, 2, 2, 3, 5, 3): [(('A:GLU:161', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 2, 2, 2, 3, 5, 3), ('A:GLU:161', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 2, 2, 2, 3, 5, 3)), (('A:GLU:163', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 2, 2, 2, 3, 5, 3), ('A:GLU:161', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 2, 2, 2, 3, 5, 3))], ('THR', 'ARG', 'VAL', 0, 0, 0, 1, 2, 2, 2, 3, 3): [(('A:THR:80', 'A:ARG:79', 'A:VAL:76', 0, 0, 0, 1, 2, 2, 2, 3, 3), ('A:THR:80', 'A:ARG:79', 'A:VAL:76', 0, 0, 0, 1, 2, 2, 2, 3, 3))], ('ARG', 'ARG', 'GLU', 0, 0, 0, 2, 1, 1, 3, 5, 3): [(('A:ARG:79', 'A:ARG:75', 'A:GLU:71', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:ARG:79', 'A:ARG:75', 'A:GLU:71', 0, 0, 0, 2, 1, 1, 3, 5, 3)), (('A:ARG:79', 'A:ARG:75', 'A:GLU:71', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:ARG:79', 'A:ARG:75', 'A:GLU:19', 0, 0, 0, 2, 1, 1, 3, 5, 3)), (('A:ARG:79', 'A:ARG:75', 'A:GLU:19', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:ARG:79', 'A:ARG:75', 'A:GLU:71', 0, 0, 0, 2, 1, 1, 3, 5, 3)), (('A:ARG:79', 'A:ARG:75', 'A:GLU:19', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:ARG:79', 'A:ARG:75', 'A:GLU:19', 0, 0, 0, 2, 1, 1, 3, 5, 3))], ('GLU', 'ALA', 'GLU', 0, 0, 0, 2, 2, 2, 3, 4, 3): [(('A:GLU:161', 'A:ALA:158', 'A:GLU:163', 0, 0, 0, 2, 2, 2, 3, 4, 3), ('A:GLU:154', 'A:ALA:158', 'A:GLU:161', 0, 0, 0, 2, 2, 2, 3, 4, 3)), (('A:GLU:154', 'A:ALA:158', 'A:GLU:161', 0, 0, 0, 2, 2, 2, 3, 4, 3), ('A:GLU:154', 'A:ALA:158', 'A:GLU:161', 0, 0, 0, 2, 2, 2, 3, 4, 3))], ('GLU', 'GLY', 'GLU', 0, 0, 0, 2, 1, 1, 2, 4, 2): [(('A:GLU:161', 'A:GLY:162', 'A:GLU:163', 0, 0, 0, 2, 1, 1, 2, 4, 2), ('A:GLU:161', 'A:GLY:162', 'A:GLU:163', 0, 0, 0, 2, 1, 1, 2, 4, 2)), (('A:GLU:161', 'A:GLY:162', 'A:GLU:163', 0, 0, 0, 2, 1, 1, 2, 4, 2), ('A:GLU:161', 'A:GLY:162', 'A:GLU:166', 0, 0, 0, 2, 1, 1, 2, 4, 2))], ('GLU', 'ARG', 'TYR', 0, 0, 0, 2, 1, 1, 3, 5, 3): [(('A:GLU:161', 'A:ARG:157', 'A:TYR:155', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:GLU:161', 'A:ARG:157', 'A:TYR:155', 0, 0, 0, 2, 1, 1, 3, 5, 3))], ('GLN', 'VAL', 'THR', 0, 0, 0, 2, 1, 1, 3, 5, 3): [(('A:GLN:72', 'A:VAL:76', 'A:THR:80', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:GLN:72', 'A:VAL:76', 'A:THR:80', 0, 0, 0, 2, 1, 1, 3, 5, 3))], ('GLN', 'GLY', 'GLU', 0, 0, 0, 2, 1, 1, 3, 5, 3): [(('A:GLN:54', 'A:GLY:56', 'A:GLU:58', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:GLN:54', 'A:GLY:56', 'A:GLU:58', 0, 0, 0, 2, 1, 1, 3, 5, 3))], ('GLU', 'GLY', 'GLU', 0, 0, 0, 2, 1, 1, 3, 4, 2): [(('A:GLU:148', 'A:GLY:151', 'A:GLU:154', 0, 0, 0, 2, 1, 1, 3, 4, 2), ('A:GLU:148', 'A:GLY:151', 'A:GLU:154', 0, 0, 0, 2, 1, 1, 3, 4, 2))], ('GLU', 'ARG', 'ILE', 0, 0, 0, 2, 1, 1, 3, 4, 3): [(('A:GLU:148', 'A:ARG:144', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 3, 4, 3), ('A:GLU:148', 'A:ARG:144', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 3, 4, 3))], ('ALA', 'GLY', 'VAL', 0, 0, 0, 2, 1, 1, 3, 5, 2): [(('A:ALA:158', 'A:GLY:162', 'A:VAL:165', 0, 0, 0, 2, 1, 1, 3, 5, 2), ('A:ALA:158', 'A:GLY:162', 'A:VAL:165', 0, 0, 0, 2, 1, 1, 3, 5, 2))], ('GLY', 'TYR', 'THR', 0, 0, 0, 2, 1, 1, 2, 3, 3): [(('A:GLY:83', 'A:TYR:84', 'A:THR:80', 0, 0, 0, 2, 1, 1, 2, 3, 3), ('A:GLY:83', 'A:TYR:84', 'A:THR:80', 0, 0, 0, 2, 1, 1, 2, 3, 3))], ('ARG', 'VAL', 'THR', 0, 0, 0, 2, 1, 1, 3, 2, 3): [(('A:ARG:79', 'A:VAL:76', 'A:THR:80', 0, 0, 0, 2, 1, 1, 3, 2, 3), ('A:ARG:79', 'A:VAL:76', 'A:THR:80', 0, 0, 0, 2, 1, 1, 3, 2, 3))], ('GLY', 'THR', 'TYR', 0, 0, 0, 2, 1, 1, 3, 2, 3): [(('A:GLY:83', 'A:THR:80', 'A:TYR:84', 0, 0, 0, 2, 1, 1, 3, 2, 3), ('A:GLY:83', 'A:THR:80', 'A:TYR:84', 0, 0, 0, 2, 1, 1, 3, 2, 3))], ('GLY', 'TYR', 'TYR', 0, 0, 0, 2, 1, 1, 2, 3, 2): [(('A:GLY:83', 'A:TYR:84', 'A:TYR:85', 0, 0, 0, 2, 1, 1, 2, 3, 2), ('A:GLY:83', 'A:TYR:84', 'A:TYR:85', 0, 0, 0, 2, 1, 1, 2, 3, 2))], ('ARG', 'ILE', 'ARG', 0, 0, 0, 1, 1, 1, 3, 2, 3): [(('A:ARG:144', 'A:ILE:142', 'A:ARG:145', 0, 0, 0, 1, 1, 1, 3, 2, 3), ('A:ARG:144', 'A:ILE:142', 'A:ARG:145', 0, 0, 0, 1, 1, 1, 3, 2, 3))], ('ARG', 'GLU', 'VAL', 0, 0, 0, 1, 2, 2, 3, 5, 3): [(('A:ARG:157', 'A:GLU:161', 'A:VAL:165', 0, 0, 0, 1, 2, 2, 3, 5, 3), ('A:ARG:157', 'A:GLU:161', 'A:VAL:165', 0, 0, 0, 1, 2, 2, 3, 5, 3))], ('TYR', 'GLY', 'TYR', 0, 0, 0, 1, 2, 2, 2, 2, 3): [(('A:TYR:84', 'A:GLY:83', 'A:TYR:85', 0, 0, 0, 1, 2, 2, 2, 2, 3), ('A:TYR:84', 'A:GLY:83', 'A:TYR:85', 0, 0, 0, 1, 2, 2, 2, 2, 3))], ('GLY', 'ALA', 'TYR', 0, 0, 0, 1, 2, 2, 3, 5, 3): [(('A:GLY:162', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 1, 2, 2, 3, 5, 3), ('A:GLY:162', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 1, 2, 2, 3, 5, 3))], ('ALA', 'GLU', 'TYR', 0, 0, 0, 2, 2, 2, 3, 3, 2): [(('A:ALA:158', 'A:GLU:154', 'A:TYR:155', 0, 0, 0, 2, 2, 2, 3, 3, 2), ('A:ALA:158', 'A:GLU:154', 'A:TYR:155', 0, 0, 0, 2, 2, 2, 3, 3, 2))], ('GLY', 'GLN', 'VAL', 0, 0, 0, 1, 2, 2, 2, 4, 3): [(('A:GLY:69', 'A:GLN:72', 'A:VAL:76', 0, 0, 0, 1, 2, 2, 2, 4, 3), ('A:GLY:69', 'A:GLN:72', 'A:VAL:76', 0, 0, 0, 1, 2, 2, 2, 4, 3))], ('GLU', 'VAL', 'HIS', 0, 0, 0, 2, 1, 1, 3, 5, 3): [(('A:GLU:161', 'A:VAL:165', 'A:HIS:169', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:GLU:161', 'A:VAL:165', 'A:HIS:169', 0, 0, 0, 2, 1, 1, 3, 5, 3))], ('GLU', 'GLN', 'LYS', 0, 0, 0, 1, 2, 2, 2, 3, 3): [(('A:GLU:71', 'A:GLN:72', 'A:LYS:68', 0, 0, 0, 1, 2, 2, 2, 3, 3), ('A:GLU:71', 'A:GLN:72', 'A:LYS:68', 0, 0, 0, 1, 2, 2, 2, 3, 3))], ('GLU', 'VAL', 'GLU', 0, 0, 0, 2, 1, 1, 3, 4, 3): [(('A:GLU:161', 'A:VAL:165', 'A:GLU:163', 0, 0, 0, 2, 1, 1, 3, 4, 3), ('A:GLU:161', 'A:VAL:165', 'A:GLU:163', 0, 0, 0, 2, 1, 1, 3, 4, 3))], ('ARG', 'GLU', 'GLY', 0, 0, 0, 1, 2, 2, 3, 4, 3): [(('A:ARG:144', 'A:GLU:148', 'A:GLY:151', 0, 0, 0, 1, 2, 2, 3, 4, 3), ('A:ARG:62', 'A:GLU:58', 'A:GLY:56', 0, 0, 0, 1, 2, 2, 3, 4, 3)), (('A:ARG:144', 'A:GLU:148', 'A:GLY:151', 0, 0, 0, 1, 2, 2, 3, 4, 3), ('A:ARG:144', 'A:GLU:148', 'A:GLY:151', 0, 0, 0, 1, 2, 2, 3, 4, 3))], ('ARG', 'ARG', 'THR', 0, 0, 0, 1, 2, 2, 3, 4, 2): [(('A:ARG:75', 'A:ARG:79', 'A:THR:80', 0, 0, 0, 1, 2, 2, 3, 4, 2), ('A:ARG:75', 'A:ARG:79', 'A:THR:80', 0, 0, 0, 1, 2, 2, 3, 4, 2))], ('ARG', 'ILE', 'TYR', 0, 0, 0, 2, 1, 1, 3, 5, 3): [(('A:ARG:145', 'A:ILE:142', 'A:TYR:84', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:ARG:145', 'A:ILE:142', 'A:TYR:84', 0, 0, 0, 2, 1, 1, 3, 5, 3))], ('GLY', 'TYR', 'ILE', 0, 0, 0, 2, 1, 1, 2, 4, 3): [(('A:GLY:83', 'A:TYR:84', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 2, 4, 3), ('A:GLY:83', 'A:TYR:84', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 2, 4, 3))], ('GLU', 'GLY', 'VAL', 0, 0, 0, 2, 1, 1, 2, 3, 2): [(('A:GLU:161', 'A:GLY:162', 'A:VAL:165', 0, 0, 0, 2, 1, 1, 2, 3, 2), ('A:GLU:161', 'A:GLY:162', 'A:VAL:165', 0, 0, 0, 2, 1, 1, 2, 3, 2)), (('A:GLU:163', 'A:GLY:162', 'A:VAL:165', 0, 0, 0, 2, 1, 1, 2, 3, 2), ('A:GLU:161', 'A:GLY:162', 'A:VAL:165', 0, 0, 0, 2, 1, 1, 2, 3, 2))], ('GLN', 'ARG', 'GLU', 0, 0, 0, 2, 1, 1, 2, 4, 3): [(('A:GLN:72', 'A:ARG:75', 'A:GLU:19', 0, 0, 0, 2, 1, 1, 2, 4, 3), ('A:GLN:65', 'A:ARG:62', 'A:GLU:58', 0, 0, 0, 2, 1, 1, 2, 4, 3))], ('ALA', 'GLU', 'LEU', 0, 0, 0, 2, 2, 2, 3, 5, 3): [(('A:ALA:158', 'A:GLU:161', 'A:LEU:109', 0, 0, 0, 2, 2, 2, 3, 5, 3), ('A:ALA:158', 'A:GLU:161', 'A:LEU:109', 0, 0, 0, 2, 2, 2, 3, 5, 3))], ('ARG', 'VAL', 'TRP', 0, 0, 0, 2, 1, 1, 3, 6, 3): [(('A:ARG:108', 'A:VAL:165', 'A:TRP:167', 0, 0, 0, 2, 1, 1, 3, 6, 3), ('A:ARG:108', 'A:VAL:165', 'A:TRP:167', 0, 0, 0, 2, 1, 1, 3, 6, 3))], ('ARG', 'ARG', 'ILE', 0, 0, 0, 1, 2, 2, 2, 3, 3): [(('A:ARG:144', 'A:ARG:145', 'A:ILE:142', 0, 0, 0, 1, 2, 2, 2, 3, 3), ('A:ARG:144', 'A:ARG:145', 'A:ILE:142', 0, 0, 0, 1, 2, 2, 2, 3, 3))], ('GLU', 'LYS', 'ILE', 0, 0, 0, 2, 1, 1, 3, 4, 3): [(('A:GLU:148', 'A:LYS:146', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 3, 4, 3), ('A:GLU:148', 'A:LYS:146', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 3, 4, 3))], ('ARG', 'LYS', 'ILE', 0, 0, 0, 2, 1, 1, 2, 3, 3): [(('A:ARG:145', 'A:LYS:146', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 2, 3, 3), ('A:ARG:145', 'A:LYS:146', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 2, 3, 3))], ('ARG', 'VAL', 'THR', 0, 0, 0, 1, 1, 1, 2, 4, 3): [(('A:ARG:75', 'A:VAL:76', 'A:THR:80', 0, 0, 0, 1, 1, 1, 2, 4, 3), ('A:ARG:75', 'A:VAL:76', 'A:THR:80', 0, 0, 0, 1, 1, 1, 2, 4, 3))], ('GLU', 'ALA', 'GLY', 0, 0, 0, 2, 2, 2, 3, 5, 3): [(('A:GLU:154', 'A:ALA:158', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 5, 3), ('A:GLU:154', 'A:ALA:158', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 5, 3))], ('GLN', 'GLY', 'LYS', 0, 0, 0, 2, 1, 1, 2, 3, 2): [(('A:GLN:72', 'A:GLY:69', 'A:LYS:68', 0, 0, 0, 2, 1, 1, 2, 3, 2), ('A:GLN:72', 'A:GLY:69', 'A:LYS:68', 0, 0, 0, 2, 1, 1, 2, 3, 2))], ('ARG', 'ARG', 'GLN', 0, 0, 0, 1, 2, 2, 2, 4, 3): [(('A:ARG:144', 'A:ARG:145', 'A:GLN:149', 0, 0, 0, 1, 2, 2, 2, 4, 3), ('A:ARG:144', 'A:ARG:145', 'A:GLN:149', 0, 0, 0, 1, 2, 2, 2, 4, 3))], ('ARG', 'ILE', 'TYR', 0, 0, 0, 1, 1, 1, 3, 5, 3): [(('A:ARG:144', 'A:ILE:142', 'A:TYR:84', 0, 0, 0, 1, 1, 1, 3, 5, 3), ('A:ARG:144', 'A:ILE:142', 'A:TYR:84', 0, 0, 0, 1, 1, 1, 3, 5, 3))], ('GLU', 'ARG', 'VAL', 0, 0, 0, 1, 1, 1, 3, 4, 2): [(('A:GLU:71', 'A:ARG:75', 'A:VAL:76', 0, 0, 0, 1, 1, 1, 3, 4, 2), ('A:GLU:71', 'A:ARG:75', 'A:VAL:76', 0, 0, 0, 1, 1, 1, 3, 4, 2))], ('GLY', 'VAL', 'TRP', 0, 0, 0, 1, 1, 1, 2, 4, 3): [(('A:GLY:162', 'A:VAL:165', 'A:TRP:167', 0, 0, 0, 1, 1, 1, 2, 4, 3), ('A:GLY:162', 'A:VAL:165', 'A:TRP:167', 0, 0, 0, 1, 1, 1, 2, 4, 3))], ('ARG', 'ALA', 'GLY', 0, 0, 0, 1, 2, 2, 2, 4, 3): [(('A:ARG:157', 'A:ALA:158', 'A:GLY:162', 0, 0, 0, 1, 2, 2, 2, 4, 3), ('A:ARG:157', 'A:ALA:158', 'A:GLY:162', 0, 0, 0, 1, 2, 2, 2, 4, 3))], ('GLU', 'GLY', 'TYR', 0, 0, 0, 2, 1, 1, 3, 5, 3): [(('A:GLU:148', 'A:GLY:151', 'A:TYR:155', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:GLU:148', 'A:GLY:151', 'A:TYR:155', 0, 0, 0, 2, 1, 1, 3, 5, 3))], ('ARG', 'GLU', 'GLN', 0, 0, 0, 1, 2, 2, 3, 4, 2): [(('A:ARG:144', 'A:GLU:148', 'A:GLN:149', 0, 0, 0, 1, 2, 2, 3, 4, 2), ('A:ARG:144', 'A:GLU:148', 'A:GLN:149', 0, 0, 0, 1, 2, 2, 3, 4, 2))], ('GLY', 'GLN', 'LYS', 0, 0, 0, 1, 2, 2, 3, 2, 2): [(('A:GLY:69', 'A:GLN:65', 'A:LYS:68', 0, 0, 0, 1, 2, 2, 3, 2, 2), ('A:GLY:69', 'A:GLN:65', 'A:LYS:68', 0, 0, 0, 1, 2, 2, 3, 2, 2))], ('ARG', 'GLU', 'LYS', 0, 0, 0, 1, 2, 2, 3, 3, 3): [(('A:ARG:144', 'A:GLU:148', 'A:LYS:146', 0, 0, 0, 1, 2, 2, 3, 3, 3), ('A:ARG:144', 'A:GLU:148', 'A:LYS:146', 0, 0, 0, 1, 2, 2, 3, 3, 3))], ('GLU', 'ALA', 'GLY', 0, 0, 0, 2, 2, 2, 3, 2, 3): [(('A:GLU:161', 'A:ALA:158', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 2, 3), ('A:GLU:161', 'A:ALA:158', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 2, 3)), (('A:GLU:163', 'A:ALA:158', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 2, 3), ('A:GLU:161', 'A:ALA:158', 'A:GLY:162', 0, 0, 0, 2, 2, 2, 3, 2, 3))], ('GLN', 'GLY', 'GLN', 0, 0, 0, 2, 1, 1, 3, 5, 2): [(('A:GLN:65', 'A:GLY:69', 'A:GLN:72', 0, 0, 0, 2, 1, 1, 3, 5, 2), ('A:GLN:65', 'A:GLY:69', 'A:GLN:72', 0, 0, 0, 2, 1, 1, 3, 5, 2))], ('ALA', 'TYR', 'ARG', 0, 0, 0, 2, 1, 1, 3, 2, 3): [(('A:ALA:158', 'A:TYR:155', 'A:ARG:157', 0, 0, 0, 2, 1, 1, 3, 2, 3), ('A:ALA:158', 'A:TYR:155', 'A:ARG:157', 0, 0, 0, 2, 1, 1, 3, 2, 3))], ('THR', 'TYR', 'TYR', 0, 0, 0, 1, 1, 1, 3, 4, 2): [(('A:THR:80', 'A:TYR:84', 'A:TYR:85', 0, 0, 0, 1, 1, 1, 3, 4, 2), ('A:THR:80', 'A:TYR:84', 'A:TYR:85', 0, 0, 0, 1, 1, 1, 3, 4, 2))], ('ARG', 'TYR', 'GLY', 0, 0, 0, 1, 1, 1, 3, 4, 3): [(('A:ARG:157', 'A:TYR:155', 'A:GLY:151', 0, 0, 0, 1, 1, 1, 3, 4, 3), ('A:ARG:157', 'A:TYR:155', 'A:GLY:151', 0, 0, 0, 1, 1, 1, 3, 4, 3))], ('ARG', 'ILE', 'LYS', 0, 0, 0, 2, 1, 1, 3, 2, 3): [(('A:ARG:145', 'A:ILE:142', 'A:LYS:146', 0, 0, 0, 2, 1, 1, 3, 2, 3), ('A:ARG:145', 'A:ILE:142', 'A:LYS:146', 0, 0, 0, 2, 1, 1, 3, 2, 3))], ('ALA', 'TYR', 'GLU', 0, 0, 0, 2, 1, 1, 3, 3, 2): [(('A:ALA:158', 'A:TYR:155', 'A:GLU:154', 0, 0, 0, 2, 1, 1, 3, 3, 2), ('A:ALA:158', 'A:TYR:155', 'A:GLU:154', 0, 0, 0, 2, 1, 1, 3, 3, 2))], ('THR', 'GLY', 'TYR', 0, 0, 0, 1, 2, 2, 3, 3, 2): [(('A:THR:80', 'A:GLY:83', 'A:TYR:84', 0, 0, 0, 1, 2, 2, 3, 3, 2), ('A:THR:80', 'A:GLY:83', 'A:TYR:84', 0, 0, 0, 1, 2, 2, 3, 3, 2))], ('ILE', 'TYR', 'THR', 0, 0, 0, 1, 1, 1, 3, 4, 3): [(('A:ILE:142', 'A:TYR:84', 'A:THR:80', 0, 0, 0, 1, 1, 1, 3, 4, 3), ('A:ILE:142', 'A:TYR:84', 'A:THR:80', 0, 0, 0, 1, 1, 1, 3, 4, 3))], ('ARG', 'ARG', 'ILE', 0, 0, 0, 2, 1, 1, 2, 3, 3): [(('A:ARG:145', 'A:ARG:144', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 2, 3, 3), ('A:ARG:145', 'A:ARG:144', 'A:ILE:142', 0, 0, 0, 2, 1, 1, 2, 3, 3))], ('GLU', 'VAL', 'TRP', 0, 0, 0, 2, 1, 1, 2, 2, 3): [(('A:GLU:166', 'A:VAL:165', 'A:TRP:167', 0, 0, 0, 2, 1, 1, 2, 2, 3), ('A:GLU:166', 'A:VAL:165', 'A:TRP:167', 0, 0, 0, 2, 1, 1, 2, 2, 3))], ('ILE', 'TYR', 'TYR', 0, 0, 0, 1, 1, 1, 3, 4, 2): [(('A:ILE:142', 'A:TYR:84', 'A:TYR:85', 0, 0, 0, 1, 1, 1, 3, 4, 2), ('A:ILE:142', 'A:TYR:84', 'A:TYR:85', 0, 0, 0, 1, 1, 1, 3, 4, 2))], ('ARG', 'GLU', 'LEU', 0, 0, 0, 1, 2, 2, 3, 4, 3): [(('A:ARG:157', 'A:GLU:161', 'A:LEU:109', 0, 0, 0, 1, 2, 2, 3, 4, 3), ('A:ARG:157', 'A:GLU:161', 'A:LEU:109', 0, 0, 0, 1, 2, 2, 3, 4, 3))], ('THR', 'GLY', 'TYR', 0, 0, 0, 1, 2, 2, 3, 4, 3): [(('A:THR:80', 'A:GLY:83', 'A:TYR:85', 0, 0, 0, 1, 2, 2, 3, 4, 3), ('A:THR:80', 'A:GLY:83', 'A:TYR:85', 0, 0, 0, 1, 2, 2, 3, 4, 3))], ('GLY', 'GLU', 'LYS', 0, 0, 0, 1, 2, 2, 3, 4, 3): [(('A:GLY:151', 'A:GLU:148', 'A:LYS:146', 0, 0, 0, 1, 2, 2, 3, 4, 3), ('A:GLY:151', 'A:GLU:148', 'A:LYS:146', 0, 0, 0, 1, 2, 2, 3, 4, 3))], ('GLY', 'VAL', 'HIS', 0, 0, 0, 1, 1, 1, 2, 4, 3): [(('A:GLY:162', 'A:VAL:165', 'A:HIS:169', 0, 0, 0, 1, 1, 1, 2, 4, 3), ('A:GLY:162', 'A:VAL:165', 'A:HIS:169', 0, 0, 0, 1, 1, 1, 2, 4, 3))], ('ILE', 'ARG', 'LYS', 0, 0, 0, 1, 2, 2, 3, 3, 2): [(('A:ILE:142', 'A:ARG:145', 'A:LYS:146', 0, 0, 0, 1, 2, 2, 3, 3, 2), ('A:ILE:142', 'A:ARG:145', 'A:LYS:146', 0, 0, 0, 1, 2, 2, 3, 3, 2))], ('ARG', 'LEU', 'GLU', 0, 0, 0, 2, 1, 1, 2, 4, 3): [(('A:ARG:108', 'A:LEU:109', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 2, 4, 3), ('A:ARG:108', 'A:LEU:109', 'A:GLU:161', 0, 0, 0, 2, 1, 1, 2, 4, 3))], ('GLU', 'VAL', 'GLU', 0, 0, 0, 2, 1, 1, 3, 4, 2): [(('A:GLU:161', 'A:VAL:165', 'A:GLU:166', 0, 0, 0, 2, 1, 1, 3, 4, 2), ('A:GLU:161', 'A:VAL:165', 'A:GLU:166', 0, 0, 0, 2, 1, 1, 3, 4, 2))], ('GLU', 'VAL', 'GLY', 0, 0, 0, 2, 1, 1, 3, 2, 2): [(('A:GLU:161', 'A:VAL:165', 'A:GLY:162', 0, 0, 0, 2, 1, 1, 3, 2, 2), ('A:GLU:161', 'A:VAL:165', 'A:GLY:162', 0, 0, 0, 2, 1, 1, 3, 2, 2)), (('A:GLU:163', 'A:VAL:165', 'A:GLY:162', 0, 0, 0, 2, 1, 1, 3, 2, 2), ('A:GLU:161', 'A:VAL:165', 'A:GLY:162', 0, 0, 0, 2, 1, 1, 3, 2, 2))], ('ARG', 'ALA', 'GLU', 0, 0, 0, 1, 2, 2, 2, 3, 3): [(('A:ARG:157', 'A:ALA:158', 'A:GLU:161', 0, 0, 0, 1, 2, 2, 2, 3, 3), ('A:ARG:157', 'A:ALA:158', 'A:GLU:161', 0, 0, 0, 1, 2, 2, 2, 3, 3)), (('A:ARG:157', 'A:ALA:158', 'A:GLU:154', 0, 0, 0, 1, 2, 2, 2, 3, 3), ('A:ARG:157', 'A:ALA:158', 'A:GLU:161', 0, 0, 0, 1, 2, 2, 2, 3, 3))], ('ARG', 'THR', 'GLY', 0, 0, 0, 2, 1, 1, 2, 3, 3): [(('A:ARG:79', 'A:THR:80', 'A:GLY:83', 0, 0, 0, 2, 1, 1, 2, 3, 3), ('A:ARG:79', 'A:THR:80', 'A:GLY:83', 0, 0, 0, 2, 1, 1, 2, 3, 3))], ('GLU', 'GLY', 'TYR', 0, 0, 0, 2, 1, 1, 2, 2, 3): [(('A:GLU:154', 'A:GLY:151', 'A:TYR:155', 0, 0, 0, 2, 1, 1, 2, 2, 3), ('A:GLU:154', 'A:GLY:151', 'A:TYR:155', 0, 0, 0, 2, 1, 1, 2, 2, 3))], ('TYR', 'THR', 'VAL', 0, 0, 0, 1, 1, 1, 3, 5, 3): [(('A:TYR:84', 'A:THR:80', 'A:VAL:76', 0, 0, 0, 1, 1, 1, 3, 5, 3), ('A:TYR:84', 'A:THR:80', 'A:VAL:76', 0, 0, 0, 1, 1, 1, 3, 5, 3))], ('GLU', 'GLN', 'VAL', 0, 0, 0, 1, 2, 2, 2, 4, 3): [(('A:GLU:71', 'A:GLN:72', 'A:VAL:76', 0, 0, 0, 1, 2, 2, 2, 4, 3), ('A:GLU:71', 'A:GLN:72', 'A:VAL:76', 0, 0, 0, 1, 2, 2, 2, 4, 3))], ('GLU', 'ALA', 'TYR', 0, 0, 0, 2, 2, 2, 3, 2, 3): [(('A:GLU:154', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 2, 2, 2, 3, 2, 3), ('A:GLU:154', 'A:ALA:158', 'A:TYR:155', 0, 0, 0, 2, 2, 2, 3, 2, 3))], ('ALA', 'TYR', 'GLY', 0, 0, 0, 2, 1, 1, 3, 4, 3): [(('A:ALA:158', 'A:TYR:155', 'A:GLY:151', 0, 0, 0, 2, 1, 1, 3, 4, 3), ('A:ALA:158', 'A:TYR:155', 'A:GLY:151', 0, 0, 0, 2, 1, 1, 3, 4, 3))], ('ARG', 'VAL', 'ARG', 0, 0, 0, 1, 1, 1, 2, 3, 3): [(('A:ARG:75', 'A:VAL:76', 'A:ARG:79', 0, 0, 0, 1, 1, 1, 2, 3, 3), ('A:ARG:75', 'A:VAL:76', 'A:ARG:79', 0, 0, 0, 1, 1, 1, 2, 3, 3))], ('ALA', 'ARG', 'TYR', 0, 0, 0, 2, 1, 1, 2, 3, 3): [(('A:ALA:158', 'A:ARG:157', 'A:TYR:155', 0, 0, 0, 2, 1, 1, 2, 3, 3), ('A:ALA:158', 'A:ARG:157', 'A:TYR:155', 0, 0, 0, 2, 1, 1, 2, 3, 3))], ('GLY', 'TYR', 'TYR', 0, 0, 0, 2, 1, 1, 3, 2, 2): [(('A:GLY:83', 'A:TYR:85', 'A:TYR:84', 0, 0, 0, 2, 1, 1, 3, 2, 2), ('A:GLY:83', 'A:TYR:85', 'A:TYR:84', 0, 0, 0, 2, 1, 1, 3, 2, 2))], ('ARG', 'ARG', 'LYS', 0, 0, 0, 1, 2, 2, 2, 3, 2): [(('A:ARG:144', 'A:ARG:145', 'A:LYS:146', 0, 0, 0, 1, 2, 2, 2, 3, 2), ('A:ARG:144', 'A:ARG:145', 'A:LYS:146', 0, 0, 0, 1, 2, 2, 2, 3, 2))], ('GLY', 'GLU', 'VAL', 0, 0, 0, 1, 2, 2, 2, 2, 3): [(('A:GLY:162', 'A:GLU:161', 'A:VAL:165', 0, 0, 0, 1, 2, 2, 2, 2, 3), ('A:GLY:162', 'A:GLU:161', 'A:VAL:165', 0, 0, 0, 1, 2, 2, 2, 2, 3)), (('A:GLY:162', 'A:GLU:163', 'A:VAL:165', 0, 0, 0, 1, 2, 2, 2, 2, 3), ('A:GLY:162', 'A:GLU:161', 'A:VAL:165', 0, 0, 0, 1, 2, 2, 2, 2, 3))], ('GLN', 'GLY', 'LYS', 0, 0, 0, 2, 1, 1, 3, 2, 2): [(('A:GLN:65', 'A:GLY:69', 'A:LYS:68', 0, 0, 0, 2, 1, 1, 3, 2, 2), ('A:GLN:65', 'A:GLY:69', 'A:LYS:68', 0, 0, 0, 2, 1, 1, 3, 2, 2))], ('GLY', 'THR', 'VAL', 0, 0, 0, 2, 1, 1, 3, 5, 3): [(('A:GLY:83', 'A:THR:80', 'A:VAL:76', 0, 0, 0, 2, 1, 1, 3, 5, 3), ('A:GLY:83', 'A:THR:80', 'A:VAL:76', 0, 0, 0, 2, 1, 1, 3, 5, 3))], ('ARG', 'THR', 'TYR', 0, 0, 0, 2, 1, 1, 2, 4, 3): [(('A:ARG:79', 'A:THR:80', 'A:TYR:84', 0, 0, 0, 2, 1, 1, 2, 4, 3), ('A:ARG:79', 'A:THR:80', 'A:TYR:84', 0, 0, 0, 2, 1, 1, 2, 4, 3))], ('ARG', 'ARG', 'VAL', 0, 0, 0, 1, 2, 2, 3, 2, 3): [(('A:ARG:75', 'A:ARG:79', 'A:VAL:76', 0, 0, 0, 1, 2, 2, 3, 2, 3), ('A:ARG:75', 'A:ARG:79', 'A:VAL:76', 0, 0, 0, 1, 2, 2, 3, 2, 3))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656828f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_residue(data, residue):\n",
    "    \"\"\"\n",
    "    Procura todas as chaves e listas do dicionário `data` \n",
    "    onde pelo menos uma tupla contenha o resíduo `residue`.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Dicionário de dados no formato que você mostrou.\n",
    "        residue (str): Nome do resíduo a procurar (ex: 'GLY').\n",
    "\n",
    "    Returns:\n",
    "        dict: Sub-dicionário contendo apenas as chaves e valores filtrados.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "\n",
    "    for key, tuples_list in data.items():\n",
    "        # Checa se o resíduo está na chave\n",
    "        key_has_residue = residue in key\n",
    "\n",
    "        # Filtra apenas os pares que contêm o resíduo em alguma das tuplas\n",
    "        filtered_pairs = [pair for pair in tuples_list if residue in pair[0] or residue in pair[1]]\n",
    "\n",
    "        if key_has_residue or filtered_pairs:\n",
    "            result[key] = filtered_pairs if filtered_pairs else tuples_list\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Exemplo de uso:\n",
    "residue = \"A:ALA:158\"\n",
    "filtered = find_residue(data, residue)\n",
    "\n",
    "for k, v in filtered.items():\n",
    "    print(f\"Chave: {k}\")\n",
    "    for pair in v:\n",
    "        print(\"   \", pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a2008c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('ASP', 'LEU', 'TRP', 0, 0, 0, 1, 1, 1, 3, 4, 2) | ('C:ASP:4', 'C:LEU:6', 'C:TRP:7', 0, 0, 0, 1, 1, 1, 3, 4, 2)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('ASP', 'LEU', 'TRP', 0, 0, 0, 1, 1, 1, 3, 5, 3) | ('C:ASP:4', 'C:LEU:6', 'C:TRP:8', 0, 0, 0, 1, 1, 1, 3, 5, 3)\n",
    "\n",
    "INFO:root:N Nodes: 49 | N Edges: 148 | N Triad: 349 | Unique Triad: 332\n",
    "DEBUG:root:Counters: {1: 316, 2: 15, 3: 1}\n",
    "DEBUG:CRSProtein:Found triad: ('TYR', 'ASP', 'VAL', 0, 0, 0, 1, 2, 2, 3, 6, 3) | ('A:TYR:155', 'C:ASP:4', 'A:VAL:66', 0, 0, 0, 1, 2, 2, 3, 6, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('TYR', 'ASP', 'VAL', 0, 0, 0, 1, 2, 2, 3, 4, 2) | ('A:TYR:155', 'C:ASP:4', 'C:VAL:5', 0, 0, 0, 1, 2, 2, 3, 4, 2)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('VAL', 'ASP', 'VAL', 0, 0, 0, 1, 2, 2, 3, 3, 2) | ('A:VAL:66', 'C:ASP:4', 'C:VAL:5', 0, 0, 0, 1, 2, 2, 3, 3, 2)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('VAL', 'VAL', 'ASP', 0, 0, 0, 1, 1, 1, 3, 3, 2) | ('A:VAL:66', 'C:VAL:5', 'C:ASP:4', 0, 0, 0, 1, 1, 1, 3, 3, 2)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('ASP', 'VAL', 'MET', 0, 0, 0, 2, 1, 1, 2, 4, 3) | ('C:ASP:4', 'C:VAL:5', 'C:MET:7', 0, 0, 0, 2, 1, 1, 2, 4, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('GLY', 'VAL', 'ASP', 0, 0, 0, 1, 1, 1, 3, 4, 2) | ('A:GLY:69', 'C:VAL:5', 'C:ASP:4', 0, 0, 0, 1, 1, 1, 3, 4, 2)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('GLY', 'TYR', 'ASP', 0, 0, 0, 1, 1, 1, 3, 5, 3) | ('A:GLY:151', 'A:TYR:155', 'C:ASP:4', 0, 0, 0, 1, 1, 1, 3, 5, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('ASP', 'TYR', 'MET', 0, 0, 0, 2, 1, 1, 3, 4, 3) | ('C:ASP:4', 'A:TYR:155', 'C:MET:7', 0, 0, 0, 2, 1, 1, 3, 4, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('ALA', 'TYR', 'ASP', 0, 0, 0, 2, 1, 1, 3, 3, 3) | ('A:ALA:158', 'A:TYR:155', 'C:ASP:4', 0, 0, 0, 2, 1, 1, 3, 3, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('GLU', 'TYR', 'ASP', 0, 0, 0, 2, 1, 1, 2, 5, 3) | ('A:GLU:154', 'A:TYR:155', 'C:ASP:4', 0, 0, 0, 2, 1, 1, 2, 5, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('ARG', 'TYR', 'ASP', 0, 0, 0, 1, 1, 1, 3, 5, 3) | ('A:ARG:157', 'A:TYR:155', 'C:ASP:4', 0, 0, 0, 1, 1, 1, 3, 5, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('GLN', 'VAL', 'ASP', 0, 0, 0, 2, 1, 1, 2, 5, 3) | ('A:GLN:65', 'A:VAL:66', 'C:ASP:4', 0, 0, 0, 2, 1, 1, 2, 5, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('ASP', 'VAL', 'VAL', 0, 0, 0, 2, 1, 1, 3, 2, 3) | ('C:ASP:4', 'A:VAL:66', 'C:VAL:5', 0, 0, 0, 2, 1, 1, 3, 2, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('GLY', 'VAL', 'ASP', 0, 0, 0, 1, 1, 1, 3, 4, 3) | ('A:GLY:69', 'A:VAL:66', 'C:ASP:4', 0, 0, 0, 1, 1, 1, 3, 4, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('ARG', 'VAL', 'ASP', 0, 0, 0, 1, 1, 1, 3, 5, 3) | ('A:ARG:62', 'A:VAL:66', 'C:ASP:4', 0, 0, 0, 1, 1, 1, 3, 5, 3)\n",
    "\n",
    "DEBUG:CRSProtein:Found triad: ('LYS', 'VAL', 'ASP', 0, 0, 0, 2, 1, 1, 3, 5, 3) | ('A:LYS:68', 'A:VAL:66', 'C:ASP:4', 0, 0, 0, 2, 1, 1, 3, 5, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ic_imuno310)",
   "language": "python",
   "name": "ic_imuno310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
